{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.19.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.4.0.46)\n",
      "Requirement already satisfied: dlib in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (19.21.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: boto3 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.17.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3) (0.3.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.4 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3) (1.20.4)\n",
      "Requirement already satisfied: six in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from botocore<1.21.0,>=1.20.4->boto3) (1.26.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy opencv-python dlib matplotlib boto3\n",
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    !pip install pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time, datetime, sys\n",
    "import zipfile as zf\n",
    "import boto3\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import dlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model name - determines where the outputs are saved\n",
    "model_name = 'G2M-faces-lr2e-3'\n",
    "\n",
    "# Variables/Hyperparameters\n",
    "dataset_size = 600\n",
    "generate_dataset = True\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "nce_layers = [0, 4, 8, 12, 16]\n",
    "lambda_NCE = 1.0\n",
    "lambda_GAN = 1.0\n",
    "batch_size = 1\n",
    "load_weights = True\n",
    "epoch = 0\n",
    "epochs = 100\n",
    "nonsaturating = False\n",
    "\n",
    "input_size = (3,180,180)\n",
    "res_blocks = 9 # def = 9\n",
    "learning_rate = 0.002\n",
    "kernel_size = 5\n",
    "init_kernel_size = 7\n",
    "\n",
    "D_losses = []\n",
    "GAN_losses = []\n",
    "NCE_losses = []\n",
    "G_total_losses = []\n",
    "\n",
    "# Swap the game and movie datasets, so that translation goes from movie to game instead\n",
    "swap = False\n",
    "\n",
    "# Toggle whether translation is done only on faces\n",
    "faces = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original data (and the processed data)\n",
    "s3 = boto3.resource('s3', aws_access_key_id = 'AKIAIOPFTDXA3ZXLK5YA', aws_secret_access_key = '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')\n",
    "bucket = s3.Bucket('vision-dataset-vmrj42')\n",
    "\n",
    "for fname in ['Data.zip', 'datasets.zip']:\n",
    "    if not os.path.isfile(fname):\n",
    "        bucket.download_file(fname, fname)\n",
    "\n",
    "if not os.path.isdir('Data'):\n",
    "    files = zf.ZipFile('Data.zip', 'r')\n",
    "    files.extractall('')\n",
    "if not os.path.isdir('dataset') and not generate_dataset:\n",
    "    files = zf.ZipFile('datasets.zip', 'r')\n",
    "    files.extractall('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a basic dataset for full-frame translation\n",
    "\n",
    "for dname in ['dataset/train/game', \n",
    "              'dataset/train/movie', \n",
    "              'dataset/test/game', \n",
    "              'dataset/test/movie', \n",
    "              'face_dataset/train/game',\n",
    "              'face_dataset/train/movie',\n",
    "              'face_dataset/test/game',\n",
    "              'face_dataset/test/movie']:\n",
    "    if not os.path.isdir(dname):\n",
    "        os.makedirs(dname)\n",
    "\n",
    "if len(os.listdir('dataset/train/game')) < dataset_size:\n",
    "    # get some frames from the game footage\n",
    "    cap = cv2.VideoCapture('Data/game/MafiaVideogame.mp4')\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_count = 0\n",
    "    saved_frames = 0\n",
    "    \n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    faces = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        # Save the entire frame as part of the dataset, alternating between the training and testing datasets\n",
    "        if frame_count % (length // (2 * dataset_size)) == 0 and ret:\n",
    "            if saved_frames < dataset_size:\n",
    "                fname = 'dataset/train/game/%d.png' % (saved_frames)\n",
    "            else:\n",
    "                fname = 'dataset/test/game/%d.png' % (saved_frames % dataset_size)\n",
    "            cv2.imwrite(fname, frame)\n",
    "            saved_frames += 1\n",
    "        \n",
    "        # Check if there is a face in every (length // (10 * dataset_size)) frame\n",
    "        if frame_count % (length // (6 * dataset_size)) == 0 and ret:\n",
    "            dets = face_detector(frame, 1)\n",
    "            for i, d in enumerate(dets):\n",
    "                left, top, right, bottom = d.left(), d.top(), d.right(), d.bottom()\n",
    "                if right - left > 60:\n",
    "                    face = frame[top:bottom, left:right]\n",
    "                    if len(face) > 0 and len(face[0]) > 0:\n",
    "                        faces.append(face)\n",
    "    cap.release()\n",
    "    \n",
    "    # Alternating between the training and testing datasets, save the extracted faces\n",
    "    saved_faces = 0\n",
    "    for i, face in enumerate(faces):\n",
    "        if i % (len(faces) // (2 * dataset_size)) == 0:\n",
    "            if saved_faces < dataset_size:\n",
    "                fname = 'face_dataset/train/game/%d.png' % (saved_faces)\n",
    "            else:\n",
    "                fname = 'face_dataset/test/game/%d.png' % (saved_faces % dataset_size)\n",
    "            cv2.imwrite(fname, cv2.resize(face, (input_size[1], input_size[1])))\n",
    "            saved_faces += 1\n",
    "\n",
    "    # get some frames from the movie footage\n",
    "    movie_dirs = ['Data/movie/TheGodfather.mp4', 'Data/movie/TheIrishman.mp4', 'Data/movie/TheSopranos.mp4']\n",
    "\n",
    "    saved_frames = 0\n",
    "    for movie in movie_dirs:\n",
    "        cap = cv2.VideoCapture(movie)\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_count += 1\n",
    "            if frame_count % (length // (2 * dataset_size / len(movie_dirs))) == 0 and ret:\n",
    "                if saved_frames < dataset_size:\n",
    "                    fname = 'dataset/train/movie/%d.png' % (saved_frames)\n",
    "                else:\n",
    "                    fname = 'dataset/test/movie/%d.png' % (saved_frames % dataset_size)\n",
    "                cv2.imwrite(fname, frame)\n",
    "                saved_frames += 1\n",
    "\n",
    "\n",
    "        cap.release()\n",
    "        \n",
    "    face_detector = dlib.get_frontal_face_detector()        \n",
    "    faces_dir = 'Data/faces/'\n",
    "    real_faces = os.listdir(faces_dir)\n",
    "    saved_faces = 0\n",
    "    current_face = 0\n",
    "    while saved_faces < dataset_size * 4:\n",
    "        real_face = cv2.imread(faces_dir + real_faces[current_face])\n",
    "        face = []\n",
    "        dets = face_detector(real_face, 1)\n",
    "        for d in dets:\n",
    "            left, top, right, bottom = d.left(), d.top(), d.right(), d.bottom()\n",
    "            if right - left > 20:\n",
    "                face = real_face[top : bottom, left : right]\n",
    "                if len(face) > 0 and len(face[0]) > 0:\n",
    "                    face = cv2.resize(face, (input_size[1], input_size[1]))\n",
    "                    if saved_faces < dataset_size * 2:\n",
    "                        fname = 'face_dataset/train/movie/%d.png' % (saved_faces)\n",
    "                    else:\n",
    "                        fname = 'face_dataset/test/movie/%d.png' % (saved_faces % (dataset_size * 2))\n",
    "                    cv2.imwrite(fname, face)\n",
    "                    saved_faces += 1\n",
    "                    break\n",
    "        current_face += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful class for loading both game and movie samples as one dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, swap = False, transforms_ = None, unaligned = False, mode = \"train\"):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "        if swap:\n",
    "            self.files_game = sorted(glob.glob(os.path.join(root, \"%s/movie\" % mode) + \"/*.*\"))\n",
    "            self.files_movie = sorted(glob.glob(os.path.join(root, \"%s/game\" % mode) + \"/*.*\"))\n",
    "        else:\n",
    "            self.files_game = sorted(glob.glob(os.path.join(root, \"%s/game\" % mode) + \"/*.*\"))\n",
    "            self.files_movie = sorted(glob.glob(os.path.join(root, \"%s/movie\" % mode) + \"/*.*\"))\n",
    "        print(len(os.listdir(os.path.join(root, 'train/movie'))))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_game = Image.open(self.files_game[index % len(self.files_game)])\n",
    "\n",
    "        if self.unaligned:\n",
    "            image_movie = Image.open(self.files_movie[random.randint(0, len(self.files_movie) - 1)])\n",
    "        else:\n",
    "            image_movie = Image.open(self.files_movie[index % len(self.files_movie)])\n",
    "\n",
    "        # Convert grayscale images to rgb\n",
    "        if image_game.mode != \"RGB\":\n",
    "            image_game = to_rgb(image_game)\n",
    "        if image_movie.mode != \"RGB\":\n",
    "            image_movie = to_rgb(image_movie)\n",
    "\n",
    "        item_game = self.transform(image_game)\n",
    "        item_movie = self.transform(image_movie)\n",
    "        \n",
    "        return {\"a\": item_game, \"b\": item_movie}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_game), len(self.files_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1200\n",
      "torch.Size([5, 3, 180, 180])\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# Define the dataset-wide transformations\n",
    "\n",
    "transforms_ = [\n",
    "    transforms.Resize(int(input_size[1] * 1.4), Image.BICUBIC),\n",
    "    transforms.RandomCrop((input_size[1],input_size[2])),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "\n",
    "\n",
    "if faces:\n",
    "    dataset_dir = 'face_dataset'\n",
    "else:\n",
    "    dataset_dir = 'dataset'\n",
    "# Training data loader\n",
    "dataloader = DataLoader(\n",
    "    ImageDataset(dataset_dir, swap = swap, transforms_ = transforms_, unaligned = True),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 0,\n",
    ")\n",
    "# Test data loader\n",
    "val_dataloader = DataLoader(\n",
    "    ImageDataset(dataset_dir, swap = swap, transforms_ = transforms_, unaligned = True, mode = 'test'),\n",
    "    batch_size = 5,\n",
    "    shuffle = True,\n",
    "    num_workers = 0,\n",
    ")\n",
    "\n",
    "imgs = next(iter(val_dataloader))\n",
    "print(imgs['a'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Utils\n",
    "\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.5/0.5, -0.5/0.5, -0.5/0.5],\n",
    "    std=[1/0.5, 1/0.5, 1/0.5]\n",
    ")\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if hasattr(m, \"bias\") and m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "        \n",
    "def sample_images(batches_done):\n",
    "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
    "    imgs = next(iter(val_dataloader))\n",
    "    G.eval()\n",
    "    real_A = Variable(imgs[\"a\"].type(Tensor))\n",
    "    fake_B = G(real_A)\n",
    "    for img in fake_B:\n",
    "        img = inv_normalize(img)\n",
    "    # Arange images along x-axis\n",
    "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    # Arange images along y-axis\n",
    "    image_grid = torch.cat((real_A, fake_B), 1)\n",
    "    if not os.path.isdir('models/%s/samples' % model_name):\n",
    "        os.makedirs('models/%s/samples' % model_name)\n",
    "    save_image(image_grid, \"models/%s/samples/%s.png\" % (model_name, batches_done), normalize=False)\n",
    "    \n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, power=2):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.power = power\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = x.pow(self.power).sum(1, keepdim=True).pow(1. / self.power)\n",
    "        out = x.div(norm + 1e-7)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator and Discriminator models adapted from https://github.com/eriklindernoren/PyTorch-GAN\n",
    "# PatchSampleF adapted from https://github.com/taesungp/contrastive-unpaired-translation\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features, kernel):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(kernel // 2),\n",
    "            nn.Conv2d(in_features, in_features, kernel),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(kernel // 2),\n",
    "            nn.Conv2d(in_features, in_features, kernel),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_shape, num_residual_blocks, kernel, init_kernel):\n",
    "        super(Generator, self).__init__()\n",
    "        channels = input_shape[0]\n",
    "\n",
    "        # Initial convolution block\n",
    "        out_features = 64\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(init_kernel // 2),\n",
    "            nn.Conv2d(channels, out_features, init_kernel),\n",
    "            nn.InstanceNorm2d(out_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        in_features = out_features\n",
    "\n",
    "        # Downsampling\n",
    "        for _ in range(2):\n",
    "            out_features *= 2\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel, stride=2, padding=kernel//2),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            in_features = out_features\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(num_residual_blocks):\n",
    "            model += [ResidualBlock(out_features, kernel)]\n",
    "\n",
    "        # Upsampling\n",
    "        for _ in range(2):\n",
    "            out_features //= 2\n",
    "            model += [\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(in_features, out_features, kernel, stride=1, padding=kernel//2),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            in_features = out_features\n",
    "\n",
    "        # Output layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(init_kernel // 2), \n",
    "            nn.Conv2d(out_features, channels, init_kernel), \n",
    "            nn.Tanh()\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x, layers = [], encode_only = False):\n",
    "        if -1 in layers:\n",
    "            layers.append(len(self.model))\n",
    "        if len(layers) > 0:\n",
    "            feat = x\n",
    "            feats = []\n",
    "            for layer_id, layer in enumerate(self.model):\n",
    "                feat = layer(feat)\n",
    "                if layer_id in layers:\n",
    "                    feats.append(feat)\n",
    "                else:\n",
    "                    pass\n",
    "                if layer_id == layers[-1] and encode_only:\n",
    "                    return feats\n",
    "            return feat, feats\n",
    "        else:\n",
    "            return self.model(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        channels, height, width = input_shape\n",
    "        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalize = True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 64, normalize=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n",
    "    \n",
    "class PatchSampleF(nn.Module):\n",
    "    def __init__(self, use_mlp = True, init_type = 'normal', init_gain = 0.02, nc = 256):\n",
    "        # potential issues: currently, we use the same patch_ids for multiple images in the batch\n",
    "        super(PatchSampleF, self).__init__()\n",
    "        self.l2norm = Normalize(2)\n",
    "        self.use_mlp = use_mlp\n",
    "        self.nc = nc  # hard-coded\n",
    "        self.mlp_init = False\n",
    "        self.init_type = init_type\n",
    "        self.init_gain = init_gain\n",
    "\n",
    "    def create_mlp(self, feats):\n",
    "        for mlp_id, feat in enumerate(feats):\n",
    "            input_nc = feat.shape[1]\n",
    "            mlp = nn.Sequential(*[nn.Linear(input_nc, self.nc), nn.ReLU(), nn.Linear(self.nc, self.nc)])\n",
    "            if torch.cuda.is_available():\n",
    "                mlp.cuda()\n",
    "            setattr(self, 'mlp_%d' % mlp_id, mlp)\n",
    "        if torch.cuda.is_available():\n",
    "            self.to(device)\n",
    "        self.apply(weights_init_normal)\n",
    "        self.mlp_init = True\n",
    "\n",
    "    def forward(self, feats, num_patches = 64, patch_ids = None):\n",
    "        return_ids = []\n",
    "        return_feats = []\n",
    "        if self.use_mlp and not self.mlp_init:\n",
    "            self.create_mlp(feats)\n",
    "        for feat_id, feat in enumerate(feats):\n",
    "            B, H, W = feat.shape[0], feat.shape[2], feat.shape[3]\n",
    "            feat_reshape = feat.permute(0, 2, 3, 1).flatten(1, 2)\n",
    "            if num_patches > 0:\n",
    "                if patch_ids is not None:\n",
    "                    patch_id = patch_ids[feat_id]\n",
    "                else:\n",
    "                    patch_id = torch.randperm(feat_reshape.shape[1], device=feats[0].device)\n",
    "                    patch_id = patch_id[:int(min(num_patches, patch_id.shape[0]))]  # .to(patch_ids.device)\n",
    "                x_sample = feat_reshape[:, patch_id, :].flatten(0, 1)  # reshape(-1, x.shape[1])\n",
    "            else:\n",
    "                x_sample = feat_reshape\n",
    "                patch_id = []\n",
    "            if self.use_mlp:\n",
    "                mlp = getattr(self, 'mlp_%d' % feat_id)\n",
    "                x_sample = mlp(x_sample)\n",
    "            return_ids.append(patch_id)\n",
    "            x_sample = self.l2norm(x_sample)\n",
    "\n",
    "            if num_patches == 0:\n",
    "                x_sample = x_sample.permute(0, 2, 1).reshape([B, x_sample.shape[-1], H, W])\n",
    "            return_feats.append(x_sample)\n",
    "        return return_feats, return_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to create separate losses for each feature, from https://github.com/taesungp/contrastive-unpaired-translation\n",
    "class PatchNCELoss(nn.Module):\n",
    "    def __init__(self, batch_size, nce_T = 0.07):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.nce_T = nce_T\n",
    "        self.cross_entropy_loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        self.mask_dtype = torch.bool\n",
    "\n",
    "    def forward(self, feat_q, feat_k):\n",
    "        batchSize = feat_q.shape[0]\n",
    "        dim = feat_q.shape[1]\n",
    "        feat_k = feat_k.detach()\n",
    "\n",
    "        # pos logit\n",
    "        l_pos = torch.bmm(feat_q.view(batchSize, 1, -1), feat_k.view(batchSize, -1, 1))\n",
    "        l_pos = l_pos.view(batchSize, 1)\n",
    "\n",
    "        batch_dim_for_bmm = self.batch_size\n",
    "\n",
    "        # reshape features to batch size\n",
    "        feat_q = feat_q.view(batch_dim_for_bmm, -1, dim)\n",
    "        feat_k = feat_k.view(batch_dim_for_bmm, -1, dim)\n",
    "        npatches = feat_q.size(1)\n",
    "        l_neg_curbatch = torch.bmm(feat_q, feat_k.transpose(2, 1))\n",
    "\n",
    "        # diagonal entries are similarity between same features, and hence meaningless.\n",
    "        # just fill the diagonal with very small number, which is exp(-10) and almost zero\n",
    "        diagonal = torch.eye(npatches, device=feat_q.device, dtype=self.mask_dtype)[None, :, :]\n",
    "        l_neg_curbatch.masked_fill_(diagonal, -10.0)\n",
    "        l_neg = l_neg_curbatch.view(-1, npatches)\n",
    "\n",
    "        out = torch.cat((l_pos, l_neg), dim=1) / self.nce_T\n",
    "\n",
    "        loss = self.cross_entropy_loss(out, torch.zeros(out.size(0), dtype=torch.long,\n",
    "                                                        device=feat_q.device))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "def nonsaturating_loss(prediction, is_real):\n",
    "    if is_real.mean() == 1:\n",
    "        loss = F.softplus(-prediction).view(prediction.size(0), -1).mean(dim = 1)\n",
    "    else:\n",
    "        loss = F.softplus(prediction).view(prediction.size(0), -1).mean(dim = 1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the networks, load the most recent saved models, and set the loss functions and optimizers\n",
    "\n",
    "if faces:\n",
    "    input_size = (input_size[0], input_size[1], input_size[1])\n",
    "G = Generator(input_size, res_blocks, kernel_size, init_kernel_size).to(device)\n",
    "D = Discriminator(input_size).to(device)\n",
    "Sampler = PatchSampleF(batch_size).to(device)\n",
    "\n",
    "if nonsaturating:\n",
    "    criterion_GAN = nonsaturating_loss\n",
    "else:\n",
    "    criterion_GAN = torch.nn.MSELoss().to(device)\n",
    "criterion_NCE = []\n",
    "\n",
    "for nce_layer in nce_layers:\n",
    "    criterion_NCE.append(PatchNCELoss(batch_size).to(device))\n",
    "\n",
    "G.apply(weights_init_normal)\n",
    "D.apply(weights_init_normal)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr = learning_rate)\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the sampler are not made until the first forward pass through the Sampler network\n",
    "# Hence, we do a 'trial' training pass before setting the optimizer for the Sampler\n",
    "for i, batch in enumerate(dataloader):\n",
    "    x, y = Variable(batch[\"a\"].type(Tensor)), Variable(batch[\"b\"].type(Tensor))\n",
    "    \n",
    "    real = Variable(Tensor(np.ones((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "    fake = Variable(Tensor(np.zeros((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "    \n",
    "    D.eval()\n",
    "    G.eval()\n",
    "    Sampler.eval()\n",
    "    # get the fake loss\n",
    "    fake_y = G(x)\n",
    "    D_fake = D(fake_y.detach())\n",
    "    loss_D_fake = criterion_GAN(D_fake, fake).mean()\n",
    "    # get the real loss\n",
    "    D_real = D(y)\n",
    "    loss_D_real = criterion_GAN(D_real, real).mean()\n",
    "    # combine loss and calculate gradients\n",
    "    loss_D = (loss_D_fake + loss_D_real) * 0.5\n",
    "    loss_D.backward()\n",
    "\n",
    "    # get the fake GAN loss\n",
    "    D_fake = D(fake_y)\n",
    "    loss_G_GAN = lambda_GAN * criterion_GAN(D_fake, real).mean()\n",
    "    total_nce_loss = 0\n",
    "    for fake, real in [(fake_y, x), (y, G(y))]:\n",
    "        # get the NCE loss\n",
    "        feat_q = G(fake, nce_layers, encode_only = True)\n",
    "        feat_k = G(real, nce_layers, encode_only = True)\n",
    "\n",
    "        feat_k_pool, sample_ids = Sampler(feat_k, 256, None)\n",
    "        feat_q_pool, _ = Sampler(feat_q, 256, sample_ids)\n",
    "\n",
    "        total_nce_loss = 0.0\n",
    "        for f_q, f_k, crit, nce_layer in zip(feat_q_pool, feat_k_pool, criterion_NCE, nce_layers):\n",
    "            loss = crit(f_q, f_k) * lambda_NCE\n",
    "            total_nce_loss += loss.mean()\n",
    "\n",
    "        nce_loss = total_nce_loss / len(nce_layers)\n",
    "        total_nce_loss += nce_loss\n",
    "\n",
    "    loss_G = loss_G_GAN + total_nce_loss\n",
    "    loss_G.backward()\n",
    "    \n",
    "    break\n",
    "\n",
    "optimizer_Sampler = torch.optim.Adam(Sampler.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the most recently saved models if available\n",
    "if os.path.isdir('models/%s' % model_name) and load_weights:\n",
    "    # Get the most recent model and load them\n",
    "    epoch = max([int(fname[8:-4]) for fname in os.listdir('models/%s' % model_name) if 'Sampler' in fname])\n",
    "    G.load_state_dict(torch.load('models/%s/G_%d.pth' % (model_name, epoch)))\n",
    "    D.load_state_dict(torch.load('models/%s/D_%d.pth' % (model_name, epoch)))\n",
    "    Sampler.load_state_dict(torch.load('models/%s/Sampler_%d.pth' % (model_name, epoch)))\n",
    "    # Load the losses as well, for plotting\n",
    "    losses = np.load('models/%s/losses_%d.npy' % (model_name, epoch))\n",
    "    D_losses = list(losses[0])\n",
    "    GAN_losses = list(losses[1])\n",
    "    NCE_losses = list(losses[2])\n",
    "    G_total_losses = list(losses[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Loop, adapted from https://github.com/taesungp/contrastive-unpaired-translation\n",
    "\n",
    "prev_time = time.time()\n",
    "for epoch in range(epoch, epochs):\n",
    "    total_D_loss = 0\n",
    "    total_GAN_loss = 0\n",
    "    total_NCE_loss = 0\n",
    "    total_G_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        x, y = Variable(batch[\"a\"].type(Tensor)), Variable(batch[\"b\"].type(Tensor))\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        real = Variable(Tensor(np.ones((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "        fake = Variable(Tensor(np.zeros((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "        \n",
    "        # train discriminator\n",
    "        D.train()\n",
    "        optimizer_D.zero_grad()\n",
    "        # get the fake loss\n",
    "        fake_y = G(x)\n",
    "        D_fake = D(fake_y.detach())\n",
    "        loss_D_fake = criterion_GAN(D_fake, fake).mean()\n",
    "        # get the real loss\n",
    "        D_real = D(y)\n",
    "        loss_D_real = criterion_GAN(D_real, real).mean()\n",
    "        # combine loss and calculate gradients\n",
    "        loss_D = (loss_D_fake + loss_D_real) * 0.5\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # train generator\n",
    "        G.train()\n",
    "        optimizer_G.zero_grad()\n",
    "        optimizer_Sampler.zero_grad()\n",
    "        # get the fake GAN loss\n",
    "        D_fake = D(fake_y)\n",
    "        loss_G_GAN = criterion_GAN(D_fake, real).mean()\n",
    "        # get the NCE loss\n",
    "        Sampler.train()\n",
    "        total_nce_loss = 0\n",
    "        for fake, real in [(fake_y, x), (y, G(y))]:\n",
    "            feat_q = G(fake_y, nce_layers, encode_only = True)\n",
    "            feat_k = G(x, nce_layers, encode_only = True)\n",
    "\n",
    "            feat_k_pool, sample_ids = Sampler(feat_k, 256, None)\n",
    "            feat_q_pool, _ = Sampler(feat_q, 256, sample_ids)\n",
    "\n",
    "            total_nce_loss = 0.0\n",
    "            for f_q, f_k, crit, nce_layer in zip(feat_q_pool, feat_k_pool, criterion_NCE, nce_layers):\n",
    "                loss = crit(f_q, f_k) * lambda_NCE\n",
    "                total_nce_loss += loss.mean()\n",
    "\n",
    "            nce_loss = total_nce_loss / len(nce_layers)\n",
    "            total_nce_loss += nce_loss\n",
    "        total_nce_loss *= 0.5\n",
    "        \n",
    "        loss_G = loss_G_GAN + total_nce_loss\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        optimizer_Sampler.step()\n",
    "        \n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        # Determine approximate time left\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        batches_left = epochs * len(dataloader) - batches_done\n",
    "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "        prev_time = time.time()\n",
    "\n",
    "        # Print log\n",
    "        sys.stdout.write(\n",
    "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [GAN loss: %f, NCE loss: %f, Total: %f] ETA: %s\"\n",
    "            % (\n",
    "                epoch,\n",
    "                epochs,\n",
    "                i,\n",
    "                len(dataloader),\n",
    "                loss_D.item(),\n",
    "                loss_G_GAN.item(),\n",
    "                nce_loss.item(),\n",
    "                loss_G.item(),\n",
    "                time_left,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        total_D_loss += loss_D.item()\n",
    "        total_GAN_loss += loss_G_GAN.item()\n",
    "        total_NCE_loss += nce_loss.item()\n",
    "        total_G_loss += loss_G.item()\n",
    "        \n",
    "        # If at sample interval save image\n",
    "        if batches_done % 300 == 0:\n",
    "            sample_images(batches_done)\n",
    "            \n",
    "    D_losses.append(total_D_loss / len(dataloader))\n",
    "    GAN_losses.append(total_GAN_loss / len(dataloader))\n",
    "    NCE_losses.append(total_NCE_loss / len(dataloader))\n",
    "    G_total_losses.append(total_G_loss / len(dataloader))\n",
    "    display.clear_output(wait = True)\n",
    "    time.sleep(1)\n",
    "    plt.clf()\n",
    "    plt.ylabel('Mean Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.plot(D_losses, color = 'r')\n",
    "    plt.plot(GAN_losses, color = 'g')\n",
    "    plt.plot(NCE_losses, color = 'b')\n",
    "    plt.savefig('models/%s/loss_plot.png' % model_name)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "    if not os.path.isdir('models'):\n",
    "        os.makedirs('models')\n",
    "    if not os.path.isdir('models/%s' % model_name):\n",
    "        os.makedirs('models/%s' % model_name)\n",
    "    torch.save(G.state_dict(), \"models/%s/G_%d.pth\" % (model_name, epoch))\n",
    "    torch.save(D.state_dict(), \"models/%s/D_%d.pth\" % (model_name, epoch))\n",
    "    torch.save(Sampler.state_dict(), \"models/%s/Sampler_%d.pth\" % (model_name, epoch))\n",
    "    np.save('models/%s/losses_%d.npy' % (model_name, epoch), np.array([D_losses, GAN_losses, NCE_losses, G_total_losses]))\n",
    "    try:\n",
    "        os.remove('models/%s/G_%d.pth' % (model_name, epoch - 1))\n",
    "        os.remove('models/%s/D_%d.pth' % (model_name, epoch - 1))\n",
    "        os.remove('models/%s/Sampler_%d.pth' % (model_name, epoch - 1))\n",
    "        os.remove('models/%s/losses_%d.npy' % (model_name, epoch - 1))\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = next(iter(val_dataloader))\n",
    "\n",
    "values = [3, 5, 7]\n",
    "dir_name = 'G2M-faces-conv'\n",
    "total_e = 99\n",
    "output_dir = 'G2M-faces-conv'\n",
    "\n",
    "for n in values:\n",
    "    G_compare = Generator(input_size, 9, n, 3).to(device)\n",
    "    G_compare.load_state_dict(torch.load('models/%s%d/G_%d.pth' % (dir_name, n, total_e)))\n",
    "    G_compare.eval()\n",
    "    \n",
    "    real_A = Variable(imgs[\"a\"].type(Tensor)).detach()\n",
    "    fake_B = G_compare(real_A)\n",
    "    for img in fake_B:\n",
    "        img = inv_normalize(img)\n",
    "    \n",
    "    # Arange images along x-axis\n",
    "    real_A_grid = make_grid(real_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    \n",
    "    # Arange images along y-axis\n",
    "    image_grid = torch.cat((real_A_grid, fake_B), 1)\n",
    "    if not os.path.isdir('comparisons/%s' % output_dir):\n",
    "        os.makedirs('comparisons/%s' % output_dir)\n",
    "    save_image(image_grid, \"comparisons/%s/%d.png\" % (output_dir, n), normalize=False)\n",
    "    \n",
    "    \n",
    "def sample_images(batches_done):\n",
    "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
    "    imgs = next(iter(val_dataloader))\n",
    "    G.eval()\n",
    "    real_A = Variable(imgs[\"a\"].type(Tensor))\n",
    "    fake_B = G(real_A)\n",
    "    for img in fake_B:\n",
    "        img = inv_normalize(img)\n",
    "    # Arange images along x-axis\n",
    "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    # Arange images along y-axis\n",
    "    image_grid = torch.cat((real_A, fake_B), 1)\n",
    "    if not os.path.isdir('models/%s/samples' % model_name):\n",
    "        os.makedirs('models/%s/samples' % model_name)\n",
    "    save_image(image_grid, \"models/%s/samples/%s.png\" % (model_name, batches_done), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game footage is 30 fps\n",
    "video_length = 30 * 30\n",
    "frames_model = 'G2M-frames-lambda-ncebiasless'\n",
    "faces_model = 'G2M-faces-lr2e-3'\n",
    "total_e = 99\n",
    "output_name = 'test-clip'\n",
    "\n",
    "frame_transforms = transforms.Compose([\n",
    "    transforms.Resize(144),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "face_transforms = transforms.Compose([\n",
    "    transforms.Resize(180),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "frame_upsample = transforms.Compose([\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.Resize((576, 1024)), \n",
    "    #transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "cap = cv2.VideoCapture('Data/game/MafiaVideogame.mp4')\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "start = random.randrange((length - video_length)//10)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "if not os.path.isdir('output_movies'):\n",
    "    os.mkdir('output_movies')\n",
    "output = cv2.VideoWriter('output_movies/%s.mp4' % output_name, fourcc, 30, (1024, 576))\n",
    "\n",
    "G_frames = Generator((3,144,256), 9, 3, 3).to(device)\n",
    "G_frames.load_state_dict(torch.load('models/%s/G_%d.pth' % (frames_model, total_e)))\n",
    "G_frames.eval()\n",
    "\n",
    "G_faces = Generator((3,180,180), 9, 5, 7).to(device)\n",
    "G_faces.load_state_dict(torch.load('models/%s/G_%d.pth' % (faces_model, total_e)))\n",
    "G_faces.eval()\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "    # Save the entire frame as part of the dataset, alternating between the training and testing datasets\n",
    "    if frame_count >= start and frame_count < start + video_length and ret:\n",
    "        output_frame = np.zeros((576,1024,3))\n",
    "        \n",
    "        quadrants = [frame[:720//2, :1280//2], frame[720//2:, :1280//2], frame[:720//2, 1280//2:], frame[720//2:, 1280//2:]]\n",
    "        quadrants = [Image.fromarray(q, 'RGB') for q in quadrants]\n",
    "        inputs = torch.stack([frame_transforms(q) for q in quadrants], dim = 0).to(device)\n",
    "        frame_outputs = G_frames(inputs).detach()\n",
    "        output_frame = torch.cat((torch.cat((frame_outputs[0], frame_outputs[1]), 1), torch.cat((frame_outputs[2], frame_outputs[3]), 1)), 2)\n",
    "        output_frame = frame_upsample(output_frame)\n",
    "        #output_frame = np.array(output_frame)\n",
    "        #output_frame = output_frame.cpu().numpy().transpose(1,2,0)\n",
    "        \n",
    "        dets = face_detector(frame, 1)\n",
    "        faces = []\n",
    "        for i, d in enumerate(dets):\n",
    "            left, top, right, bottom = d.left(), d.top(), d.right(), d.bottom()\n",
    "            if right - left > 20:\n",
    "                face = frame[top:bottom, left:right]\n",
    "                face = torch.stack([face_transforms(Image.fromarray(face, 'RGB'))], dim = 0).to(device)\n",
    "                output_face = G_faces(face).squeeze(0).detach()\n",
    "                left = int(left * 1024/1280)\n",
    "                top = int(top * 1024/1280)\n",
    "                right = int(right * 1024/1280)\n",
    "                bottom = int(bottom * 1024/1280)\n",
    "                face_upsample = transforms.Compose([\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                    transforms.Resize((bottom-top, right-left)), \n",
    "                    #transforms.ToPILImage()\n",
    "                ])\n",
    "                output_face = face_upsample(output_face)\n",
    "                #output_face = np.array(output_face)\n",
    "                #output_face = output_face.cpu().numpy().transpose(1,2,0)\n",
    "                output_frame[:,top:bottom, left:right] = output_face\n",
    "        \n",
    "        save_image(output_frame, 'output_movies/test.png', normalize=True)\n",
    "        #cv2.imwrite('output_movies/test.png', output_frame)\n",
    "        output.write(cv2.imread('output_movies/test.png', 1))\n",
    "    if frame_count >= start + video_length:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
