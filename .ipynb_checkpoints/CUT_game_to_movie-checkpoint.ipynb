{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.19.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.4.0.46)\n",
      "Requirement already satisfied: dlib in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (19.21.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: boto3 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.17.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3) (0.3.4)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.4 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3) (1.20.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from botocore<1.21.0,>=1.20.4->boto3) (1.26.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy opencv-python dlib matplotlib boto3\n",
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    !pip install pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time, datetime, sys\n",
    "import zipfile as zf\n",
    "import boto3\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import dlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model name - determines where the outputs are saved\n",
    "model_name = 'G2M-frames-conv5'\n",
    "\n",
    "# Variables/Hyperparameters\n",
    "dataset_size = 600\n",
    "generate_dataset = True\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "nce_layers = [0, 4, 8, 12, 16]\n",
    "lambda_NCE = 1.0\n",
    "lambda_GAN = 1.0\n",
    "batch_size = 1\n",
    "load_weights = True\n",
    "epoch = 0\n",
    "epochs = 100\n",
    "nonsaturating = False\n",
    "\n",
    "input_size = (3,144,256)\n",
    "res_blocks = 9 # def = 9\n",
    "learning_rate = 0.002\n",
    "kernel_size = 5\n",
    "init_kernel_size = 7\n",
    "\n",
    "D_losses = []\n",
    "GAN_losses = []\n",
    "NCE_losses = []\n",
    "G_total_losses = []\n",
    "\n",
    "# Swap the game and movie datasets, so that translation goes from movie to game instead\n",
    "swap = False\n",
    "\n",
    "# Toggle whether translation is done only on faces\n",
    "faces = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original data (and the processed data)\n",
    "s3 = boto3.resource('s3', aws_access_key_id = 'AKIAIOPFTDXA3ZXLK5YA', aws_secret_access_key = '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')\n",
    "bucket = s3.Bucket('vision-dataset-vmrj42')\n",
    "\n",
    "for fname in ['Data.zip', 'datasets.zip']:\n",
    "    if not os.path.isfile(fname):\n",
    "        bucket.download_file(fname, fname)\n",
    "\n",
    "if not os.path.isdir('Data'):\n",
    "    files = zf.ZipFile('Data.zip', 'r')\n",
    "    files.extractall('')\n",
    "if not os.path.isdir('dataset') and not generate_dataset:\n",
    "    files = zf.ZipFile('datasets.zip', 'r')\n",
    "    files.extractall('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a basic dataset for full-frame translation\n",
    "\n",
    "for dname in ['dataset/train/game', \n",
    "              'dataset/train/movie', \n",
    "              'dataset/test/game', \n",
    "              'dataset/test/movie', \n",
    "              'face_dataset/train/game',\n",
    "              'face_dataset/train/movie',\n",
    "              'face_dataset/test/game',\n",
    "              'face_dataset/test/movie']:\n",
    "    if not os.path.isdir(dname):\n",
    "        os.makedirs(dname)\n",
    "\n",
    "if len(os.listdir('dataset/train/game')) < dataset_size:\n",
    "    # get some frames from the game footage\n",
    "    cap = cv2.VideoCapture('Data/game/MafiaVideogame.mp4')\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_count = 0\n",
    "    saved_frames = 0\n",
    "    \n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    faces = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        # Save the entire frame as part of the dataset, alternating between the training and testing datasets\n",
    "        if frame_count % (length // (2 * dataset_size)) == 0 and ret:\n",
    "            if saved_frames < dataset_size:\n",
    "                fname = 'dataset/train/game/%d.png' % (saved_frames)\n",
    "            else:\n",
    "                fname = 'dataset/test/game/%d.png' % (saved_frames % dataset_size)\n",
    "            cv2.imwrite(fname, frame)\n",
    "            saved_frames += 1\n",
    "        \n",
    "        # Check if there is a face in every (length // (10 * dataset_size)) frame\n",
    "        if frame_count % (length // (6 * dataset_size)) == 0 and ret:\n",
    "            dets = face_detector(frame, 1)\n",
    "            for i, d in enumerate(dets):\n",
    "                left, top, right, bottom = d.left(), d.top(), d.right(), d.bottom()\n",
    "                if right - left > 60:\n",
    "                    face = frame[top:bottom, left:right]\n",
    "                    if len(face) > 0 and len(face[0]) > 0:\n",
    "                        faces.append(face)\n",
    "    cap.release()\n",
    "    \n",
    "    # Alternating between the training and testing datasets, save the extracted faces\n",
    "    saved_faces = 0\n",
    "    for i, face in enumerate(faces):\n",
    "        if i % (len(faces) // (2 * dataset_size)) == 0:\n",
    "            if saved_faces < dataset_size:\n",
    "                fname = 'face_dataset/train/game/%d.png' % (saved_faces)\n",
    "            else:\n",
    "                fname = 'face_dataset/test/game/%d.png' % (saved_faces % dataset_size)\n",
    "            cv2.imwrite(fname, cv2.resize(face, (input_size[1], input_size[1])))\n",
    "            saved_faces += 1\n",
    "\n",
    "    # get some frames from the movie footage\n",
    "    movie_dirs = ['Data/movie/TheGodfather.mp4', 'Data/movie/TheIrishman.mp4', 'Data/movie/TheSopranos.mp4']\n",
    "\n",
    "    saved_frames = 0\n",
    "    for movie in movie_dirs:\n",
    "        cap = cv2.VideoCapture(movie)\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_count += 1\n",
    "            if frame_count % (length // (2 * dataset_size / len(movie_dirs))) == 0 and ret:\n",
    "                if saved_frames < dataset_size:\n",
    "                    fname = 'dataset/train/movie/%d.png' % (saved_frames)\n",
    "                else:\n",
    "                    fname = 'dataset/test/movie/%d.png' % (saved_frames % dataset_size)\n",
    "                cv2.imwrite(fname, frame)\n",
    "                saved_frames += 1\n",
    "\n",
    "\n",
    "        cap.release()\n",
    "        \n",
    "    face_detector = dlib.get_frontal_face_detector()        \n",
    "    faces_dir = 'Data/faces/'\n",
    "    real_faces = os.listdir(faces_dir)\n",
    "    saved_faces = 0\n",
    "    current_face = 0\n",
    "    while saved_faces < dataset_size * 4:\n",
    "        real_face = cv2.imread(faces_dir + real_faces[current_face])\n",
    "        face = []\n",
    "        dets = face_detector(real_face, 1)\n",
    "        for d in dets:\n",
    "            left, top, right, bottom = d.left(), d.top(), d.right(), d.bottom()\n",
    "            if right - left > 60:\n",
    "                face = real_face[top : bottom, left : right]\n",
    "                if len(face) > 0 and len(face[0]) > 0:\n",
    "                    face = cv2.resize(face, (input_size[1], input_size[1]))\n",
    "                    if saved_faces < dataset_size * 2:\n",
    "                        fname = 'face_dataset/train/movie/%d.png' % (saved_faces)\n",
    "                    else:\n",
    "                        fname = 'face_dataset/test/movie/%d.png' % (saved_faces % (dataset_size * 2))\n",
    "                    cv2.imwrite(fname, face)\n",
    "                    saved_faces += 1\n",
    "                    break\n",
    "        current_face += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful class for loading both game and movie samples as one dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, swap = False, transforms_ = None, unaligned = False, mode = \"train\"):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "        if swap:\n",
    "            self.files_game = sorted(glob.glob(os.path.join(root, \"%s/movie\" % mode) + \"/*.*\"))\n",
    "            self.files_movie = sorted(glob.glob(os.path.join(root, \"%s/game\" % mode) + \"/*.*\"))\n",
    "        else:\n",
    "            self.files_game = sorted(glob.glob(os.path.join(root, \"%s/game\" % mode) + \"/*.*\"))\n",
    "            self.files_movie = sorted(glob.glob(os.path.join(root, \"%s/movie\" % mode) + \"/*.*\"))\n",
    "        print(len(os.listdir(os.path.join(root, 'train/movie'))))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_game = Image.open(self.files_game[index % len(self.files_game)])\n",
    "\n",
    "        if self.unaligned:\n",
    "            image_movie = Image.open(self.files_movie[random.randint(0, len(self.files_movie) - 1)])\n",
    "        else:\n",
    "            image_movie = Image.open(self.files_movie[index % len(self.files_movie)])\n",
    "\n",
    "        # Convert grayscale images to rgb\n",
    "        if image_game.mode != \"RGB\":\n",
    "            image_game = to_rgb(image_game)\n",
    "        if image_movie.mode != \"RGB\":\n",
    "            image_movie = to_rgb(image_movie)\n",
    "\n",
    "        item_game = self.transform(image_game)\n",
    "        item_movie = self.transform(image_movie)\n",
    "        \n",
    "        return {\"a\": item_game, \"b\": item_movie}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_game), len(self.files_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# Define the dataset-wide transformations\n",
    "\n",
    "transforms_ = [\n",
    "    transforms.Resize(int(input_size[1] * 1.4), Image.BICUBIC),\n",
    "    transforms.RandomCrop((input_size[1],input_size[2])),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "\n",
    "\n",
    "if faces:\n",
    "    dataset_dir = 'face_dataset'\n",
    "else:\n",
    "    dataset_dir = 'dataset'\n",
    "# Training data loader\n",
    "dataloader = DataLoader(\n",
    "    ImageDataset(dataset_dir, swap = swap, transforms_ = transforms_, unaligned = True),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 0,\n",
    ")\n",
    "# Test data loader\n",
    "val_dataloader = DataLoader(\n",
    "    ImageDataset(dataset_dir, swap = swap, transforms_ = transforms_, unaligned = True, mode = 'test'),\n",
    "    batch_size = 5,\n",
    "    shuffle = True,\n",
    "    num_workers = 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Utils\n",
    "\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.5/0.5, -0.5/0.5, -0.5/0.5],\n",
    "    std=[1/0.5, 1/0.5, 1/0.5]\n",
    ")\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if hasattr(m, \"bias\") and m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "        \n",
    "def sample_images(batches_done):\n",
    "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
    "    imgs = next(iter(val_dataloader))\n",
    "    G.eval()\n",
    "    real_A = Variable(imgs[\"a\"].type(Tensor))\n",
    "    fake_B = G(real_A)\n",
    "    for img in fake_B:\n",
    "        img = inv_normalize(img)\n",
    "    # Arange images along x-axis\n",
    "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    # Arange images along y-axis\n",
    "    image_grid = torch.cat((real_A, fake_B), 1)\n",
    "    if not os.path.isdir('models/%s/samples' % model_name):\n",
    "        os.makedirs('models/%s/samples' % model_name)\n",
    "    save_image(image_grid, \"models/%s/samples/%s.png\" % (model_name, batches_done), normalize=False)\n",
    "    \n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, power=2):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.power = power\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = x.pow(self.power).sum(1, keepdim=True).pow(1. / self.power)\n",
    "        out = x.div(norm + 1e-7)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator and Discriminator models adapted from https://github.com/eriklindernoren/PyTorch-GAN\n",
    "# PatchSampleF adapted from https://github.com/taesungp/contrastive-unpaired-translation\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features, kernel):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(kernel // 2),\n",
    "            nn.Conv2d(in_features, in_features, kernel),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(kernel // 2),\n",
    "            nn.Conv2d(in_features, in_features, kernel),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_shape, num_residual_blocks, kernel, init_kernel):\n",
    "        super(Generator, self).__init__()\n",
    "        channels = input_shape[0]\n",
    "\n",
    "        # Initial convolution block\n",
    "        out_features = 64\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(init_kernel // 2),\n",
    "            nn.Conv2d(channels, out_features, init_kernel),\n",
    "            nn.InstanceNorm2d(out_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        in_features = out_features\n",
    "\n",
    "        # Downsampling\n",
    "        for _ in range(2):\n",
    "            out_features *= 2\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel, stride=2, padding=kernel//2),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            in_features = out_features\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(num_residual_blocks):\n",
    "            model += [ResidualBlock(out_features, kernel)]\n",
    "\n",
    "        # Upsampling\n",
    "        for _ in range(2):\n",
    "            out_features //= 2\n",
    "            model += [\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(in_features, out_features, kernel, stride=1, padding=kernel//2),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            in_features = out_features\n",
    "\n",
    "        # Output layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(init_kernel // 2), \n",
    "            nn.Conv2d(out_features, channels, init_kernel), \n",
    "            nn.Tanh()\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x, layers = [], encode_only = False):\n",
    "        if -1 in layers:\n",
    "            layers.append(len(self.model))\n",
    "        if len(layers) > 0:\n",
    "            feat = x\n",
    "            feats = []\n",
    "            for layer_id, layer in enumerate(self.model):\n",
    "                feat = layer(feat)\n",
    "                if layer_id in layers:\n",
    "                    feats.append(feat)\n",
    "                else:\n",
    "                    pass\n",
    "                if layer_id == layers[-1] and encode_only:\n",
    "                    return feats\n",
    "            return feat, feats\n",
    "        else:\n",
    "            return self.model(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        channels, height, width = input_shape\n",
    "        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalize = True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 64, normalize=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n",
    "    \n",
    "class PatchSampleF(nn.Module):\n",
    "    def __init__(self, use_mlp = True, init_type = 'normal', init_gain = 0.02, nc = 256):\n",
    "        # potential issues: currently, we use the same patch_ids for multiple images in the batch\n",
    "        super(PatchSampleF, self).__init__()\n",
    "        self.l2norm = Normalize(2)\n",
    "        self.use_mlp = use_mlp\n",
    "        self.nc = nc  # hard-coded\n",
    "        self.mlp_init = False\n",
    "        self.init_type = init_type\n",
    "        self.init_gain = init_gain\n",
    "\n",
    "    def create_mlp(self, feats):\n",
    "        for mlp_id, feat in enumerate(feats):\n",
    "            input_nc = feat.shape[1]\n",
    "            mlp = nn.Sequential(*[nn.Linear(input_nc, self.nc), nn.ReLU(), nn.Linear(self.nc, self.nc)])\n",
    "            if torch.cuda.is_available():\n",
    "                mlp.cuda()\n",
    "            setattr(self, 'mlp_%d' % mlp_id, mlp)\n",
    "        if torch.cuda.is_available():\n",
    "            self.to(device)\n",
    "        self.apply(weights_init_normal)\n",
    "        self.mlp_init = True\n",
    "\n",
    "    def forward(self, feats, num_patches = 64, patch_ids = None):\n",
    "        return_ids = []\n",
    "        return_feats = []\n",
    "        if self.use_mlp and not self.mlp_init:\n",
    "            self.create_mlp(feats)\n",
    "        for feat_id, feat in enumerate(feats):\n",
    "            B, H, W = feat.shape[0], feat.shape[2], feat.shape[3]\n",
    "            feat_reshape = feat.permute(0, 2, 3, 1).flatten(1, 2)\n",
    "            if num_patches > 0:\n",
    "                if patch_ids is not None:\n",
    "                    patch_id = patch_ids[feat_id]\n",
    "                else:\n",
    "                    patch_id = torch.randperm(feat_reshape.shape[1], device=feats[0].device)\n",
    "                    patch_id = patch_id[:int(min(num_patches, patch_id.shape[0]))]  # .to(patch_ids.device)\n",
    "                x_sample = feat_reshape[:, patch_id, :].flatten(0, 1)  # reshape(-1, x.shape[1])\n",
    "            else:\n",
    "                x_sample = feat_reshape\n",
    "                patch_id = []\n",
    "            if self.use_mlp:\n",
    "                mlp = getattr(self, 'mlp_%d' % feat_id)\n",
    "                x_sample = mlp(x_sample)\n",
    "            return_ids.append(patch_id)\n",
    "            x_sample = self.l2norm(x_sample)\n",
    "\n",
    "            if num_patches == 0:\n",
    "                x_sample = x_sample.permute(0, 2, 1).reshape([B, x_sample.shape[-1], H, W])\n",
    "            return_feats.append(x_sample)\n",
    "        return return_feats, return_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to create separate losses for each feature, from https://github.com/taesungp/contrastive-unpaired-translation\n",
    "class PatchNCELoss(nn.Module):\n",
    "    def __init__(self, batch_size, nce_T = 0.07):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.nce_T = nce_T\n",
    "        self.cross_entropy_loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        self.mask_dtype = torch.bool\n",
    "\n",
    "    def forward(self, feat_q, feat_k):\n",
    "        batchSize = feat_q.shape[0]\n",
    "        dim = feat_q.shape[1]\n",
    "        feat_k = feat_k.detach()\n",
    "\n",
    "        # pos logit\n",
    "        l_pos = torch.bmm(feat_q.view(batchSize, 1, -1), feat_k.view(batchSize, -1, 1))\n",
    "        l_pos = l_pos.view(batchSize, 1)\n",
    "\n",
    "        batch_dim_for_bmm = self.batch_size\n",
    "\n",
    "        # reshape features to batch size\n",
    "        feat_q = feat_q.view(batch_dim_for_bmm, -1, dim)\n",
    "        feat_k = feat_k.view(batch_dim_for_bmm, -1, dim)\n",
    "        npatches = feat_q.size(1)\n",
    "        l_neg_curbatch = torch.bmm(feat_q, feat_k.transpose(2, 1))\n",
    "\n",
    "        # diagonal entries are similarity between same features, and hence meaningless.\n",
    "        # just fill the diagonal with very small number, which is exp(-10) and almost zero\n",
    "        diagonal = torch.eye(npatches, device=feat_q.device, dtype=self.mask_dtype)[None, :, :]\n",
    "        l_neg_curbatch.masked_fill_(diagonal, -10.0)\n",
    "        l_neg = l_neg_curbatch.view(-1, npatches)\n",
    "\n",
    "        out = torch.cat((l_pos, l_neg), dim=1) / self.nce_T\n",
    "\n",
    "        loss = self.cross_entropy_loss(out, torch.zeros(out.size(0), dtype=torch.long,\n",
    "                                                        device=feat_q.device))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "def nonsaturating_loss(prediction, is_real):\n",
    "    if is_real.mean() == 1:\n",
    "        loss = F.softplus(-prediction).view(prediction.size(0), -1).mean(dim = 1)\n",
    "    else:\n",
    "        loss = F.softplus(prediction).view(prediction.size(0), -1).mean(dim = 1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the networks, load the most recent saved models, and set the loss functions and optimizers\n",
    "\n",
    "if faces:\n",
    "    input_size = (input_size[0], input_size[1], input_size[1])\n",
    "G = Generator(input_size, res_blocks, kernel_size, init_kernel_size).to(device)\n",
    "D = Discriminator(input_size).to(device)\n",
    "Sampler = PatchSampleF(batch_size).to(device)\n",
    "\n",
    "if nonsaturating:\n",
    "    criterion_GAN = nonsaturating_loss\n",
    "else:\n",
    "    criterion_GAN = torch.nn.MSELoss().to(device)\n",
    "criterion_NCE = []\n",
    "\n",
    "for nce_layer in nce_layers:\n",
    "    criterion_NCE.append(PatchNCELoss(batch_size).to(device))\n",
    "\n",
    "G.apply(weights_init_normal)\n",
    "D.apply(weights_init_normal)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr = learning_rate)\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the sampler are not made until the first forward pass through the Sampler network\n",
    "# Hence, we do a 'trial' training pass before setting the optimizer for the Sampler\n",
    "for i, batch in enumerate(dataloader):\n",
    "    x, y = Variable(batch[\"a\"].type(Tensor)), Variable(batch[\"b\"].type(Tensor))\n",
    "    \n",
    "    real = Variable(Tensor(np.ones((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "    fake = Variable(Tensor(np.zeros((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "    \n",
    "    D.eval()\n",
    "    G.eval()\n",
    "    Sampler.eval()\n",
    "    # get the fake loss\n",
    "    fake_y = G(x)\n",
    "    D_fake = D(fake_y.detach())\n",
    "    loss_D_fake = criterion_GAN(D_fake, fake).mean()\n",
    "    # get the real loss\n",
    "    D_real = D(y)\n",
    "    loss_D_real = criterion_GAN(D_real, real).mean()\n",
    "    # combine loss and calculate gradients\n",
    "    loss_D = (loss_D_fake + loss_D_real) * 0.5\n",
    "    loss_D.backward()\n",
    "\n",
    "    # get the fake GAN loss\n",
    "    D_fake = D(fake_y)\n",
    "    loss_G_GAN = lambda_GAN * criterion_GAN(D_fake, real).mean()\n",
    "    total_nce_loss = 0\n",
    "    for fake, real in [(fake_y, x), (y, G(y))]:\n",
    "        # get the NCE loss\n",
    "        feat_q = G(fake, nce_layers, encode_only = True)\n",
    "        feat_k = G(real, nce_layers, encode_only = True)\n",
    "\n",
    "        feat_k_pool, sample_ids = Sampler(feat_k, 256, None)\n",
    "        feat_q_pool, _ = Sampler(feat_q, 256, sample_ids)\n",
    "\n",
    "        total_nce_loss = 0.0\n",
    "        for f_q, f_k, crit, nce_layer in zip(feat_q_pool, feat_k_pool, criterion_NCE, nce_layers):\n",
    "            loss = crit(f_q, f_k) * lambda_NCE\n",
    "            total_nce_loss += loss.mean()\n",
    "\n",
    "        nce_loss = total_nce_loss / len(nce_layers)\n",
    "        total_nce_loss += nce_loss\n",
    "\n",
    "    loss_G = loss_G_GAN + total_nce_loss\n",
    "    loss_G.backward()\n",
    "    \n",
    "    break\n",
    "\n",
    "optimizer_Sampler = torch.optim.Adam(Sampler.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the most recently saved models if available\n",
    "if os.path.isdir('models/%s' % model_name) and load_weights:\n",
    "    # Get the most recent model and load them\n",
    "    epoch = max([int(fname[8:-4]) for fname in os.listdir('models/%s' % model_name) if 'Sampler' in fname])\n",
    "    G.load_state_dict(torch.load('models/%s/G_%d.pth' % (model_name, epoch)))\n",
    "    D.load_state_dict(torch.load('models/%s/D_%d.pth' % (model_name, epoch)))\n",
    "    Sampler.load_state_dict(torch.load('models/%s/Sampler_%d.pth' % (model_name, epoch)))\n",
    "    # Load the losses as well, for plotting\n",
    "    losses = np.load('models/%s/losses_%d.npy' % (model_name, epoch))\n",
    "    D_losses = list(losses[0])\n",
    "    GAN_losses = list(losses[1])\n",
    "    NCE_losses = list(losses[2])\n",
    "    G_total_losses = list(losses[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEJCAYAAACZjSCSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9uUlEQVR4nO3dd3gUVffA8e8JIYReQqQ3KSoC0gWxIAgiKvZeX/EFsRf8ieXVAFZAsIAvAhbkVQQUpYOICKiA9N6R3kJCQkvP+f1xN6QXymZD9nyeZ5/szt6dObOzmTP33pk7oqoYY4zxXwG+DsAYY4xvWSIwxhg/Z4nAGGP8nCUCY4zxc5YIjDHGz1kiMMYYP+e1RCAiwSLyt4isEpF1ItI3izKPiki4iKz0PB73VjzGGGOyFujFeccBHVT1uIgUBf4QkRmquihDuXGq+rQX4zDGGJMDryUCdVeqHfe8LOp5nPXVaxUrVtTatWuf7WyMMcavLFu27LCqhmb1njdrBIhIEWAZUA8YpqqLsyh2h4hcDWwGXlDV3VnMpwfQA6BmzZosXbrUi1EbY0zhIyI7s3vPq53Fqpqkqk2B6kBrEWmUocgUoLaqNgFmA6Ozmc8IVW2pqi1DQ7NMaMYYY85Qvpw1pKpRwFygS4bpEaoa53k5CmiRH/EYY4xJ5c2zhkJFpJzneXGgE7AxQ5kqaV52AzZ4Kx5jjDFZ82YfQRVgtKefIAAYr6pTRaQfsFRVJwPPikg3IBGIBB71YjzGGGOyIOfbMNQtW7ZU6yw2xpjTIyLLVLVlVu/ZlcXGGOPnLBEYY4yf85tEsHYtvPEGHD7s60iMMaZg8ZtEsHkzvPMO7Nvn60iMMaZg8ZtEUKaM+3v0qG/jMMaYgsZvEkHp0u6vJQJjjEnPbxKB1QiMMSZrfpcIjh3zbRzGGFPQ+F0isBqBMcak5zeJoGRJELFEYIwxGflNIggIcB3GlgiMMSY9v0kEYInAGGOy4leJoEwZSwTGGJORJQJjjPFzfpcI7PRRY4xJz+8SgdUIjDEmPUsExhjj5/wqEdhZQ8YYk5lfJYKUGsF5dndOY4zxKr9LBKpw4oSvIzHGmILD7xIBWPOQMcak5ZeJwE4hNcaYVF5LBCISLCJ/i8gqEVknIn2zKFNMRMaJyFYRWSwitb0VD1iNwBhjsuLNGkEc0EFVLwOaAl1EpE2GMt2BI6paDxgCfODFeOwuZcYYkwWvJQJ1jnteFvU8Mp6vcwsw2vP8B6CjiIi3YrIagTHGZObVPgIRKSIiK4FDwGxVXZyhSDVgN4CqJgLRQEgW8+khIktFZGl4ePgZx2OJwBhjMvNqIlDVJFVtClQHWotIozOczwhVbamqLUNDQ884HksExhiTWb6cNaSqUcBcoEuGt/YCNQBEJBAoC0R4K46UPgI7a8gYY1J586yhUBEp53leHOgEbMxQbDLwiOf5ncBvqt677rdYMfewGoExxqQK9OK8qwCjRaQILuGMV9WpItIPWKqqk4EvgDEishWIBO71YjyAjTdkjDEZeS0RqOpqoFkW099M8zwWuMtbMWTFRiA1xpj0/OrKYrBEYIwxGVkiMMYYP2eJwBhj/JxfJgI7fdQYY1L5XSKws4aMMSY9v0sE1jRkjDHp+WUiiI2F+HhfR2KMMQWDXyYCsH4CY4xJ4beJwJqHjDHG8dtEYDUCY4xx/C4R2F3KjDEmPb9LBNY0ZIwx6VkiMMYYP2eJwBhj/JwlAmOM8XN+lwhKlgQRSwTGGJPC7xJBQIA7c8hOHzXGGMfvEgHYwHPGGJOWXyYCG3jOGGNSWSIwxhg/Z4nAGGP8nCUCY4zxc15LBCJSQ0Tmish6EVknIs9lUaa9iESLyErP401vxZOWJQJjjEkV6MV5JwIvqepyESkNLBOR2aq6PkO5Bap6kxfjyMROHzXGmFReqxGo6n5VXe55fgzYAFTz1vJOR0qNQNXXkRhjjO/lSx+BiNQGmgGLs3i7rYisEpEZInJpNp/vISJLRWRpeHj4WcdTpoxLAidOnPWsjDHmvOf1RCAipYAfgedVNWPL/HKglqpeBnwK/JzVPFR1hKq2VNWWoaGhZx2TjTdkjDGpvJoIRKQoLgl8q6oTM76vqkdV9bjn+XSgqIhU9GZMYInAGGPS8uZZQwJ8AWxQ1cHZlKnsKYeItPbEE+GtmFKULev+Hjni7SUZY0zB582zhtoBDwFrRGSlZ9prQE0AVR0O3An0EpFEIAa4V9X7Xbg1a7q/O3ZA27beXpoxxhRsXksEqvoHILmUGQoM9VYM2bnwQvd327b8XrIxxhQ8fnllcYkSUKWKJQJjjAE/TQQAdetaIjDGGLBEYIwxfs+vE8G+fRAT4+tIjDHGt/w6EQBs3+7bOIwxxtcsEVgiMMb4Ob9PBNZPYIzxd36bCEJC3HDUlgiMMf7ObxOBiJ05ZIwx4MeJACwRGGMMWCLgn38gKcnXkRhjjO/4fSJISIA9e3wdiTHG+I7fJwKw5iFjjH+zRIAlAmOMf/PrRFCjBhQtaonAGOPf/DoRFCkCtWtbIjDG+LdcE4GI3CUipT3P3xCRiSLS3Puh5Q87hdQY4+/yUiP4j6oeE5Ergetw9yH+r3fDyj8picD7N8g0xpiCKS+JIOUs+xuBEao6DQjyXkj568IL4ehRiIz0dSTGGOMbeUkEe0Xkc+AeYLqIFMvj584LKWcOrVrl2ziMMcZX8rJDvxuYBVyvqlFABeBlbwaVn665BipVghdegPh4X0djjDH5Ly+JoAowTVW3iEh74C7gb28GlZ/KlYMRI2D1aujf39fRGGNM/stLIvgRSBKResAIoAbwXW4fEpEaIjJXRNaLyDoReS6LMiIin4jIVhFZ7auzkbp1g0cegffeg78LTYozxpi8yUsiSFbVROB24FNVfRlXS8hNIvCSqjYE2gBPiUjDDGVuAOp7Hj3w4dlIH30EVaq4hGAdx8YYf5KXRJAgIvcBDwNTPdOK5vYhVd2vqss9z48BG4BqGYrdAnyjziKgnIjkJcmcc+XKwZdfwubN7iKz116D8HBfRGKMMfkrL4ngX0Bb4B1V/UdE6gBjTmchIlIbaAYszvBWNWB3mtd7yJwsEJEeIrJURJaGe3Hv3KkTrFgBXbrA++9DnTp2NpExpvDLNRGo6nqgN7BGRBoBe1T1g7wuQERK4foZnlfVo2cSpKqOUNWWqtoyNDT0TGaRZ02awPjxsGYNxMTAxIleXZwxxvhcYG4FPGcKjQZ2AALUEJFHVHV+Hj5bFJcEvlXVrHape3Gdzymqe6b53KWXQuPGsHChryMxxhjvykvT0IdAZ1W9RlWvBq4HhuT2IRER3HAUG1R1cDbFJgMPe84eagNEq+r+PMbudW3bwuLFkJzs60iMMcZ78pIIiqrqppQXqrqZPHQWA+2Ah4AOIrLS8+gqIk+IyBOeMtOB7cBWYCTw5OmF711t2rjhJ9av93UkxhjjPbk2DQFLRWQU8D/P6weApbl9SFX/wDUl5VRGgafyEINPtG3r/i5cCI0a+TYWY4zxlrzUCHoB64FnPY/1wBM5fqKQqF8fQkJg0SJfR2KMMd6Ta41AVeOAwZ4HACLyJ67pp1ATcc1D1mFsjCnMznQU0ZrnNIoCrG1b2LABjhzxdSTGGOMdZ5oI/OY2Lm3auL+LM14KZ4wxhUS2TUMicnt2bwHFvRNOwdO6NQQEuOahLl18HY0xxpx7OfUR3JzDe1NzeK9QKV3anTFkHcbGmMIq20Sgqv/Kz0AKsrZt4fvv3YVlAYXm3mzGGOPYbi0P2raF6GjXaWyMMYWNJYI8aOc5UXbSJN/GYYwx3mCJIA/q1YMbb4QBAyAiwtfRGGPMuZWnRCAiV4jI/SLycMrD24EVNAMGwLFjdl9jY0zhk2siEJExwCDgSqCV59HSy3EVOA0bQvfu8NlnsG2br6MxxphzJy+DzrUEGnoGiPNrffvCd9/Bq6+6m9cYY0xhkJemobVAZW8Hcj6oUgV694YJE2z8IWNM4ZGXRFARWC8is0RkcsrD24EVVL17u4TwzDOQlOTraIwx5uzlpWkozNtBnE9KlYLBg+G++2DkSHjCLwbkNsYUZnK+Nf23bNlSly7N9b44XqUKHTvCypWweTNUrOjTcIwxJlciskxVszzRJy9nDbURkSUiclxE4kUkSUSOnvswzx8iMHSoO5301Vd9HY0xxpydvPQRDAXuA7bgRh19HBjmzaDOBw0bwgsvwKhRMG+er6Mxxpgzl6cLylR1K1BEVZNU9SvABmQG/vOf1KuOf/nF19EYY8yZyUsiOCkiQcBKERkgIi/k8XOFXunSMH9+ajIYOzbvn1WFZ5+Ff/0Ltm71XozGGJObvOzQH/KUexo4AdQA7vBmUOeTKlVc09AVV8D998Pjj8OSJW5HnyI5OfPnhg2DTz+FMWPg4ouhRw/Yuzf/4jbGmBS5JgJV3Ym7K1kVVe2rqi96mopyJCJfisghEVmbzfvtRSRaRFZ6Hm+efvgFQ9myMGsW9Orlrjxu3RqaNYNOnaBuXShWDLp2hfBwV37FCnjpJVeL2LULnnwSRo92ySSljDHG5Je8nDV0M7ASmOl53TSPF5R9Te59CQtUtann0S8P8yywgoPdOET797u/JUq4s4ouvxx69oTffnPJ4Zdf4J57IDQUvv4aqlaFTz6BP/6AQ4fgzjshIcHXa2OM8Sd5aRoKA1oDUQCquhKok9uHVHU+EHnmoZ2fypZ1NYO//nK3t/zuO3eq6cKFrmZw/fVu0Lrvvkt//UGrVu4MpPnz4fnnfRa+McYP5eXK4gRVjRaRtNPO1VVobUVkFbAP6K2q67IqJCI9gB4ANWvWPEeLzl/NmsGyZfDyy9C8OVx9deYyDzwAq1bBwIEuodx3H1x6qRvK4vff4ccfYe1aiI+HuDgICYHbb3e1iMo2GpQx5gzlemWxiHwBzAH64DqJnwWKqmqugyuISG1gqqo2yuK9MkCyqh4Xka7Ax6paP7d5FoQri70pKcnt2H/+2b2uUMH9jYyEkiVdzaF4cVe72LIF1q1z91Fu2NBd6JaQ4Jqbhg1zndBnStU97B7NxhQOOV1ZnJcawTPA60AcMBaYBZz17VlU9Wia59NF5DMRqaiqh8923uezIkXgp59gxw53NtK8ee6so9tug86dXRJIa906GDfODXcRGOgec+dCy5YuGTzySN6We/gwfPQRfPMNREXByZMQFOSaq+6//9yuozGmYPHqWEO51AgqAwdVVUWkNfADUCu3+x4U9hrBubB3r2tmmjcPunWDFi1c01HJkrBzp+ujOHTIdVhXqeI6tb/4AmJi4Kab3JlOJUu6hJLSz3HPPb5eK2PM2TijGkFuZwapardcFjoWaA9UFJE9wFtAUc9nhwN3Ar1EJBGIAe61m9+cG9WqwZw58PbbrqN6coYtWbkyXHABLF8OBw+6JqD773fjJjVsmFruxAm44QaXVAIC4K678nc9jDH5I9sagYiEA7txzUGLcdcSnKKqPhlhx2oEpy8+3tUAjh+HGjXc0X6KpCTX8VyiRNafPX4cunRxZ0GVKAGJia4voksXdxFc586uOcsYU7CdaR9BZaATbsC5+4FpwNjszuwxBVdQEFSvnvV7RYpknwTA3X9hxgz48EPXhBQY6JLDhAmuQ7taNXca7MmT7lGqlDubKTQUHn0Ubr01dV6qrqmpenWXkIwxBUOe+ghEpBguIQwE+qrqUG8Hlh2rERQM8fEwaRJ8/707U6lkSdeRffy4O8Np61bXH3H33W4ojV273NXU8+e7cv/5j3sdFOTrNTHGP+RUI0BVs30AxYDbgQnAEuA/QLWcPuPtR4sWLdQUfPHxqm+/rRoUpFq6tDsZNTRUdcgQ1dtvd68vvlh11CjVrVtVk5NVDx1S/fBD1csuU23XTnXcONWEhMzzPnFCdeVK1a++Uv33v1UbNVK98krVTZtyjik5Oef3ly1Tfeop1UWLsi8THa360Ueqa9fm8gV4LF2q2rSp6rBheStvjLcASzW7fX22b8A3wHLgbaBRduXy+2GJ4Pyybp1q166qffqoRkWlTp82TbVu3ZSrFVSrVlUtWtQ9v/zy1Pdq1FC97z7VG290yaFWrdTPgGq5cqpduqiGhKiWKqX6/feZY1iwQLVjR9XgYNVmzVT/9S/V4cPTxzN2rHs/Zb7XXKM6fXr65LF7t2qTJqll2rVT/eabrJOVquqPP6oWL+6SIbgkZ4yv5JQIcuosTsaNNgrpryQWV5HQMmdXUTkz1jRUeKjChg3uNNc//nBnMz32WOrV1NOmuXGY/vkHypVzV1tXqQIXXeQejRu7i+YCAmD3brj3XtepfdNNrg+idGl3NfecOe4sqTvucE1WK1e6wf1KloQHH3R9JEOGwJVXusH/Jk1y96XeswcaNXJXgzds6Po7jh6Fr75y13mMGOFuVdq2rRtFtm5dt14xMa5P5T//gTZt4Icf3E2MJkyA99+HV17J/F1s3erGq8quL2f3bte/Uru2u6jQmNN1xk1DBfFhNQKTnfh4V/OoXdvVEIoVU61c2R2JnziRWi452TXZ/Otfrgyo9uihGheXWiYuTvXrr12zU0oNoFo11VWr0s/n229draRkSdXBg1Wfeca9BtV771U9edKVTUhQvf9+N/2661RHjnRNYT//rHrttanLqF1b9cEHVZ9+2v3t2tXVitLWgm67TXXjxjP/njZuVP3lF9WkpLyV37/f1XwOHMhb+fh41dmzVcPDzzxGc+5xJjWCgspqBOZ0qLrTXbMTEeFqJe3aZV1OFWbOdLWTPn2yPmLfs8edITVnjuv8vv12+Pe/4dpr088zKQnee8+NOrttW+r0GjXcUOTFi7ua0Z9/QmysqwWVKwf167v4Lr8cZs+GDz5wtY4rr3S1nhIl3FhWTz/tztrKztq17tqS8ePdejVt6ubVqZN7/+BB19lft25q3BMnutOEIyKgaFG3bo895mIuVcrFV7p06jKWLXP35Fi50n0Xt94K3btD+/bpTwxISnJXxe/e7ZZ78CDs2+cehw65Wt2LL7plZhQdDSNHQvny8PDDWZdJ2S6xse7GUb4SGwtTprjvtGlT3w7ZYjUCY7wsKUl1/vy8HQUnJ7uO6b59VcePz76PITsHD6o+95zrIG/eXLV+fVdTqFxZ9fPPVWNjXW1j40bVSZNUe/d2/S7g+lH69HEd7bVru2l167rpaWs+jz2WWoNp0UJ11izV559Pre2kfdStq/rAA6o9e6oWKeLiGDXKla9QwZUpVky1bVvXGd+5c+oJBBn7exo2dMsD15+zYkXqeh89qvruu6rly6d+pl4917+TsXYzd64rFxDgansptZlDh9y6f/qp6t69WX+/CQmuNti7t+q2bae3bdLav1+1TZvUWCtUUL3jjsx9T/kFqxEYU7j99Zfry/jrr8zvBQW5foXrr3c1j5AQNz0uDoYPd/fKqF3bHTkHBcGvv7rH0aPw+uuuryPlqPvkSXcKcHS0u64kPByWLnXDrO/f72oDAwe6mgK4I+KZM11NZ9Eid1OmCy+Eq65ytZx69aBSJfdIO47WxIku1ogIV/s4fNgtD1xtoW9fV3t47TVYswYuucTd+vWhh9wovY8/7ubdsaNbx+Bg1/f099+pdw8MCHC1tltucTHVrAmbNrn13bjR1YoCA939RJ57ztWW9uxx30v9+m6ZRYu69Rs3zs27fXt3ynT58q72FBnplh8Q4GqMM2bAgQOuz+n5590FmTVr5lxrPVdyqhFYIjCmkFCFqVPd0CEhIW7k2po13QCEwcGnN6/ERLfjS9mh52XZsbGZB0U8G5GR0L+/SzYVK7pHp06uiSxFcrLbCX/4oWuWKl3aJYyOHV0nfblybpTeN95wHfw33ODG3ypRwo2h9e23sH17+uVecolrQrv8crf8UaNcU1ZWgoPdeoeEuPLz57vvDVwCmzzZNQmliI93TXMffuiaz8CdBNGoEdSq5U6GqFLFJZKUpsFLLnHTzpYlAmNMoabqaiVDh7ozxAYOzL7vIOPn9u93Fz/u3OmGd+/WLf2wKZs3uxpSpUquj6hUKTdtwwbXn9Gli0s8RYu6vptZs9x9RXr2zP4+IaquJrV8Oaxe7fpv9uxxscTEZC5fs6ZLNA8+6OI7E5YIjDHmPKDqmp6OHHHNbxERLqksXuya1nr0cM1hZ+Js70dQKPy6/Vdem/MaU+6bQqVSlXwdjjHGZCLimorKlk2d1qFD6vPsmqjOlt/cfypAAliybwmrD672dSjGGHNGvDXSr98kgsYXNAZgzaE1Po7EGGMKFr9JBKElQ6lcqrLVCIwxJgO/SQQATSo1sRqBMcZk4FeJoPEFjVl3aB2JyYm+DsUYYwoMv0oETSo1IS4pjq2RW30dijHGFBh+lQhSOoytn8AYY1L5VSK4JPQSikgR1hy0fgJjjEnhV4kgODCYBiENWH3IagTGGJPCa4lARL4UkUMisjab90VEPhGRrSKyWkSaeyuWtJpUamJNQ8YYk4Y3awRfA11yeP8GoL7n0QP4rxdjOaXxBY3ZEbWDo3FH82NxxhhT4HktEajqfCAyhyK3AN947pmwCCgnIudgsNWcNanUBIC1h7KsqBhjjN/xZR9BNWB3mtd7PNMyEZEeIrJURJaGh4ef1UIbV/IMNWEdxsYYA5wnncWqOkJVW6pqy9DQ0LOaV62ytSgdVNr6CYwxxsOXiWAvUCPN6+qeaV4lIjSu1NiGmjDGGA9fJoLJwMOes4faANGquj8/FtzkAnfm0Pl2Ux5jjPEGb54+OhZYCFwkIntEpLuIPCEiT3iKTAe2A1uBkcCT3oolo8aVGhMdF82u6F35tUhjjCmwvHaHMlW9L5f3FXjKW8vPybW1ryVAAvjgzw/47MbPfBGCMcYUGOdFZ/G5dknoJTzb+lmGLx3Owt0LT02fvW021QZXY+WBlb4Lzhhj8plfJgKAftf2o1qZavSc2pOEpAT+3PUnt3x/C/uO7ePPXX/6OjxjjMk3fpsIShcrzdAbhrLm0Bp6TetF1++6UqNsDUoULcGWyC2+Ds8YY/KN3yYCgFsuvoXbLr6NL1Z8Qbngcvz60K80CGnA5ojNvg7NGGPyjdc6i88XQ7sOpULxCrzS7hVqlK1Bg5AGLNu3zNdhGWNMvvHrGgFA1dJVGdVtFPVD6gNQv0J9dkTtID4p3seRGWNM/vD7RJBRg5AGJGkS/xz5x9ehGGNMvrBEkEGDkAYA1mFsjPEblggyqF/BNRFZh7Exxl9YIsggpEQIFYpXsERgjPEblgiy0CCkgTUNGWP8hiWCLNSvUN9qBMYYv2GJIAsNQhqw5+geTiac9HUoxhjjdZYIspBy5tDWyK0+jsQYY7zPEkEW7MwhY4w/sUSQhZSrjLdEWIexMabws0SQhVJBpahauiqbI61GYIwp/CwRZMPOHDLm/BaTEMOJ+BOZph+JOcK6Q+sy3bM8WZO9MsZYVGwUyZqcp7Lbj2zn5rE389OGn855HDnx+9FHs9MgpAE/b/zZ12GYAmBH1A5GLBvBK+1eoWxw2Tx9JlmTCRD/Pc5KTE4kMCB/di+qioikm3Y8/jhXfXUVu6J3MajTIB5t+igA49aN4+npTxMRE0GtsrW49eJbqVOuDvN2zmPeznnEJsbyRIsn6H1Fb6qUrgJAfFI8u6N3ExkTSWRMJPFJ8VxY/kLqVqhLcGAwqkp0XDQn4k9QtXTVU7FsOryJ1357jYkbJlKiaAkahjakaaWmvHH1G9QqVyvTeszbMY87xt9BREwEM7fO5Me7f6TbRd28++V5WCLIRoOQBoSfDCcqNopyweV8Hc45d/jkYSqWqJhu2obwDTw781k+6/rZqX4Sf7fp8CauG3Mde47uQRDe6fhOrp9ZsncJXb7twutXvc6LbV88Z7EkJCVQtEjRPJWNTYyl17Re7D+2n2n3T6NIQJEsyyUmJ7ItctupK+rPNHnFJ8UzYd0Eft/xOwt2LWBL5BZ6NO/BoM6DKBlU8rTmNWnjJGqUrUHzKs2zXdZfu/9iwc4F/LXnLxbvWUzzKs0Ze8dYQkuGkqzJPPrzo6w+uJpmlZvx2OTH+Gb1N1QoXoGJGybSulpr+l3WjxlbZzB86XDikuKoVbYWt1x0C/FJ8Xy8+GOGLRlGhzod2Bm9k80Rm0lMTswUhyCElAghOjaahOQEAEKKh9C6WmvKBZdj/LrxFC9anN5te5OQnMC68HWMXTuWaVumMeOBGVxW+TLAHTSMWj6Kp6Y/Rd3ydZn14Cx6TevFXRPuYsp9U+hct/Op9Y5PiqdUUKnT+j7zQjJWjwq6li1b6tKlS72+nEkbJ3HruFv5+/G/aVWtldeXl58G/TWIV+e8ysLuC2lZteWp6ff+cC/j1o2jQ50O/PrQr5mOsgqLmIQYomKjTh3xZWf1wdV0GtMJgIahDVmydwnbn9vOBSUvyPYzB48fpMWIFuw/vh9V5ed7fz51VBefFM+XK77kyppX0uiCRuk+F3EygrLBZTMdRc/fOZ/x68azeO9iVh1YxRU1rmDa/dNy3LlGxkRy6/e3smDXAgCG3zicni17Ziq3IXwDD0x8gBUHVgAQGBBIk0pNmHrf1EzfTWxiLMGBwVkub872OTw1/Sk2RWyiXHA52tVoR8USFflm1TfUq1CPUd1GERUbxY8bfmTGlhkkazKli5WmfHB5nrv8OR5p+sipefWb14+3fn8LgI51OvJ/7f6PmmVrsjliM5sOb2Leznn8vuN3TiScQBAaXdCIZlWaMX7deKqWrsrU+6Yyft14wuaFMbjzYJ5r8xxfLP+Cl2e/TExiDP3a9+OlK1469T0fiztGVGwUNcrWOBXDtshtvP/H+/y5+0/qh9Tn0tBLaRDSgIolKlI+uDyBAYFsP7KdzRGb2X98P+WDyxNaMpSgIkGs2L+CxXsX80/UP3Rv1p03rn4j3e9l7aG1dPlfF47FH2PCXRM4cPwAA/4cwLrwdXSu25lxd46jXHA5ImMi6TC6A5siNtGqait2RO1g77G9vHbla/Tv0D/bbZ8TEVmmqi2zfFNVvfYAugCbgK1AnyzefxQIB1Z6Ho/nNs8WLVpofth8eLMShn686ON8WV5+2X9sv5Z6t5QShl4/5vpT07dGbNWAvgF6ydBLlDB0zKox+RrX0dijeuj4IU1KTko3/WT8yUzTzsT2yO363oL3tOPojlqsfzElDL1nwj266fCmTGVPxp/U4UuGa/n3y2u1D6vpxvCNuiF8gwb0DdAXZ76Y7TLiEuO03RfttPjbxfXPXX9qyxEttdS7pXT1gdW69uBabTq8qRKGFutfTD9a+JEmJSfp8bjj+vqc1zWof5B2GN1BYxJiTs3v122/amC/QC35Tklt/3V77Tmlpwb0DdDrx1yvcYlxp8rN2zFPP1n0iX614isdt3acXjz0Yg3qH6Rj14zV9l+315APQjTiZMSp8snJyTrs72Fa/O3iGvJBiH6y6BP9eNHH2md2Hy35TkltNaKVnow/qaqqSclJ+vyM57Vov6I67O9hmpycfGo+e4/u1bsn3K2EoXU/rqtTNk1Jt63m/jNXaw6pqYShhKHl3i+nD058UJ+c+qQ+NPEhbf55cyUM7TG5h8YmxOpbc99SwtCHf3pYB/wxQKsMqnLqsymPuh/X1SenPqmTNk7SIzFHTi1r8Z7FWmlgpVO/7Ud+eiRdrOEnwnVn1M48/lrOXtplZ7Qrapc2HNbw1Do1+qyRfrPyG01ISkhX7tDxQ3rjtzfq1V9drQ//9LC++dubOm/HvDOOCViq2e2rs3vjbB9AEWAbcCEQBKwCGmYo8ygw9HTme1aJICpKNYcNlFHLES210WeNctyoBcHyfcv1zd/e1B/W/aDbI7fnGO9jPz+mRfsV1SemPKGEofN3zFdV1V5Te2lQ/yDdHb1b24xqo6EDQtPtPM6FxXsWa9PhTbXViFb63oL3dEP4Bp2+ebrePeFuDeofpIShRfoW0SqDqmjVD6tq8NvBShhaa0gtHblspMYnxp/W8pKSk/TPXX/qHePu0IC+AUoY2uS/TfTFmS/q//3yf1rynZJapG8RvXvC3frar6/ph399qK/9+ppWHFBRCUNbjWil2yO3n5rfoz8/qsX6F9M90XuyXFbPKT2VMPT7Nd+rquqe6D1aZVAVrTSwkhbrX0xDB4TqmFVj9ObvblbC0PZft9cag2soYWjnMZ2VMPS272/ThKQEXX9ovZZ9r6w2+qyRRsVEnVrOqGWjTiWxFftXaJf/dcm0syz3fjn9/Z/fVVV19YHVGtA3QJ+e9rSqqkacjNBuY7udOhDYd3RfuvWYtHGSSpjo3RPu1vjEeH3kp0eUMLT+J/WVMLTnlJ4akxCjQxcP1dLvltbgt4O13+/90iWwtKJiovSjhR/pzC0z0yUvVdWEpATtM7uPEsap7+Gxnx87lUxiE2J17JqxOmbVGF28Z7FGnozMcXvvOLJDmw1vpld/dXW28RQUkScj9eVfXtZpm6fl2/7FV4mgLTArzetXgVczlMm/RPDdd251t27N80dGLhuphKF/7PzjzJaZD/Ye3auVB1VOtyOoMqiKvj7n9UxHQMv2LVMJE+09q7eeiD+hlQdV1qu/uloPHj+owW8Ha/dJ3VVVddWBVVqkbxF9fNLjOS47MSlRNx/enOsOOik5SQf8MUAD+wVqzSE1tdWIVuniDfkgRJ+d/qx+sugTfX3O69p9UnftPqm79p7VW9+e97a2HtlaCUPrfFRHP1r4kW4M36jJycmalJykf+z8Q5+e9rRe8cUVesnQS7TyoMpa8p2SGtgvMN2Osc/sProrale6uA4eP6jPzXhOKw2spEX6FlHCUAkT7Ta2m87bMS/TP+j2yO1atF9R7TW116lpycnJOmvrrFNHt6/MfiXdZ5bsXaKl3i2l3cZ204PHD576zPAlw7XEOyX0sv9epgt2LlBV1Y8XfayEoff/eL/W/qi2VhpYSXcc2ZHp+/zgjw/SrdvAPwfqvqP7dFvkNl2xf4WGnwhPV/6paU9pQN8A/WL5F1pzSE0t2q+oDlk4JNua1oA/Bpw6+iYM7T+vvyYmJeqrv76qhKFl3yurhKGdvumkWyPy/v+UnZ82/KTl3i+nPaf0POvaX8rvwmSWUyLwWh+BiNwJdFHVxz2vHwIuV9Wn05R5FHjP0zy0GXhBVXfnNN8z7iNYtgxatoTx4+Guu/L0kePxx6k2uBq3XHQL39z2zekv8zTtO7aPqZunMmXzFLZGbj3VOXRRyEUM7DSQZlWapSsfnxRP+6/bs/rgauY9Og9FWb5/OVM3T2XalmkAXF/3errW78p1F15Hjyk92Hh4I1ue2ULZ4LIM/Xsoz8x4hva12zNvxzw2PLWBiypeBMDLv7zMoIWDqFehHvUq1KNu+bqUCy5HqaBSBEgAi/Ys4vcdv3Mk9ghVS1elZ4ue/Lv5v9O1LSclJzFz60w+XPghc3fM5Y5L7mDkzSMpX7w8u6J3MW3zNCqXqsyNDW4kqEhQtt+LqjJ9y3Te+v0tlu1395OuUca16e4+uptiRYrRpnobQkuGUj64PGWKlaFYkWIEFQmiepnq3NPonlw72JI1maNxR0lKTiKkREi25Z6c9iQjl4+kfe32BAcGc/jkYRbtWUTtcrXp174fDzZ5MFPfSlxiHMUCi2Wa19G4o5QsWjJdR+5bc9+i3/x+FA8szrxH52XbP/XhXx8SERNB7yt6U6F4hRzXLTImkvqf1icyJpLa5Woz/s7xOfZ7qSrdJ3fnq5Vf8ekNn/J061P/soxdM5aBfw2k9xW9ua/RfeesHyk/zzLyVzn1Efg6EYQAx1U1TkR6Aveoaocs5tUD6AFQs2bNFjt37jz9gOLioHRpePFFeP/9PH/sqWlP8cWKL9j74t4cdxBnIy4xjod+eogJ6ycAUKdcHVpUbUFwYDCBAYFM2zyNiJgIejTvwVvt36JyqcoA9Jrai+HLhjP+zvHcdWn65LYzaicjlo1g7Nqx/BOVetvNz2/6nB4tepxaboOhDdgVvYvbLr6NifdMPFUuJiGGwQsHs/rQarZGbmX7ke0cjTt66nzoWmVr0bFOR5pXac6UzVOYtW0WgQGB1K9Qnzrl61ClVBVmbp3J3mN7qVSyEmHtw+jZoudZ7zi2RW5j9vbZzN4+m6TkJO5seCfdLupGmWJlzmq+eXXw+EGemv4U+4/vJzYxFoBHLnuEni16ZrmzP12qyrAlw2h0QSPa125/1vNLMWXTFGZunck7Hd/J01lwyZrM3qN703WimvObrxJBWyBMVa/3vH4VQFXfy6Z8ESBSVXM8Ufuszhpq3hxCQmD27Dx/ZPXB1Vw2/DIGdx7MC21f4EjMEYYtGcaWyC0cPH7Q9e7X6cCLbV9Md3bA3qN7KRlU8tQ/XUxCDF+s+IKhfw+lboW6fH7T51QvU524xDhuH38707dMp0+7PjzQ5AEuDb003Q4zKjaKt+a+xbAlw0jSJMoWK0u1MtVYH76eV9q9wvvX5ZzYth/Zzuxtszl04hCvXfVauiPQ0StH89jkx1jYfSGtq7XOcT6qSmxiLHFJcZl2Jlsjt/L1yq9ZH76e7Ue2s/voblpVbUWPFj24ucHNeT7t0RjjHb5KBIG45p6OwF5gCXC/qq5LU6aKqu73PL8NeEVV2+Q037NKBP/+N/z4I0REwGkcmV7xxRVExETwUtuXeG3Oa0TGRFKjbA0qlaxE8aLFWbBzAcGBwfy7+b9J1mRmbZt16sY29SvU57LKlzF/53wOnThEq6qtWB++nqAiQQztOpRv13zL9C3Tsz3FL6314euZvmU6O6N2siN6BxeWu5DB1w/O9hzxvDp04lCOp0QaY85/PkkEngV3BT7CnUH0paq+IyL9cJ0Wk0XkPaAbkAhEAr1UdWNO8zyrRDB8OPTqBf/8A7Vr5/ljo1eO5tFJjwJwda2r+aTLJ6cuBgF30dG7f7zLt6u/JahIEO1rt6fThZ2ITYxlyb4lrDiwgosrXsyrV77KVTWvYtuRbTw48UEW713swspDEsgXx4/D55/D009DsbNv5jDGFBw+SwTecFaJYMkSaN0afvgB7rgjzx+LTYzluRnPcW2da7nn0nuybeeOOBlByaCS2V54k1ZiciIfL/qYamWqcW+je/Mci1cNHgwvvQSjR8PDD/s6GmPMOZRTIvCvwVAaN4bAQHcG0WkIDgzm85s/595G9+bY2RlSIiRPSQDcVZwvXfHSuU0CSUnw+utwzTVwIvNgW6ccPAgffgiJGS6bHzPG/f3223MXkzGmwPOvRBAcDJdeCsuX+zqScy86Grp1g3ffhfnzYeDA7Mu++ir07g3jxqVOW7MGVq6EmjXh11/hwAGvh3zeWL4cHnoIDh/2dSTGeIV/JQKAFi1cjeA8axLL0bZtcPnl8Msvrh/knnvggw9g166sy37juSbivfcg2TM87pgxrrY0ZoybljZJ+LN586B9e/jf/2DYMF9HY4xX+GciOHwYdud43Zqzdi1s2gQnT7rEsXw59O0L7dpB/fpQuTJUqAAffZT5s+HhEBubt5hU4b//heeec/0Xhw65nfGBA65fY+/e7D8bHQ1du7p1mjMHevaEAQPce//3f5nLv/suFC0KgwbBunUwebJrUvr2W+jSBa6+Gpo1s+YhgKlT3XdSvTpccYXrSE9I8HVUxpx72V1yXFAfZz3o3MKFbqiJn37KudyaNa5cyqN4cfdXRLVNG9X771ft0UP12mvd9O++S/3s1KmqJUqoVq+u+uWXqomJbnp4uCv3R5ohKxIS3HxAtWjR1OWlfV68uOo332SOMSlJ9ZZbVIsUUZ2XYTCqt95yn50/P3Xatm2u7HPPueVeeKFqq1aqs2e7suPHu3KDBrnXmzfn7TvNze+/q+7JMD7P4cOqDzyg+p//qMbFZf05X5o0STUwULVlS7fdpkxJ/x3l5MQJ1bffVt2wIf305GT32zh40DsxG5MDfDHWkLceZ50ITp50O8M33si53MCB7uv5739V331X9dlnVb/+WvXQofTlYmNVr75aNSjI7YxHjnTzb9bM7WRBtVEj1XbtVAMCUnfu7dur/vKL25GD6uuvux3iX3+pvvee6iuvqA4dqjpxouo117gyPXqoxqQZTOudd9z0IUMyx3/ihEtEl16qumCB2wk99phqcLDqPs9AY59/7j5/ySWqZcumznvPHpfw3nor6+8mKkp17lyXMLp3Vx01SvXo0azLDh7sllGqlFufpCTVJUtUa9Z0O1pQvewy1VWrct4eaR07pvr336o//OCWPXCg254vvOC+o/793fqfqcWLXfJt1Uo1OtpNS0xUrVXLbbecREe73wO473TOHDf9xAmX+ED14ovzngwWLFDt3Vu1Y0fVihXdPFIOLHJz5Ijq3r05l9mwwW3nkSNdwo44BwMNLligeuedqitXnv28zsbrr6s+8og76DGWCDJp3Fj1hhtyLnP99W4HmRcREe6fO6XWcP31bmeVnOyOIBs3donhzTdVFy1yO+7KlVNrGEOH5jz/hATVPn1c+dBQ1bZtVW+/3X32vvuyH1F16lTV0qVTdz4ptYEUsbGqVau69x/PMMDctdeq1qvn5p2Q4HZcI0eqdurk5pOS0MqWdX9LlFB96CG340vyDPo1YIB779ZbVTt3ds+bNnVJs1YtlxAmT1a94AI37frr3Xa58UbVrl1Vu3Rxy+vQwe1c27ZVrV07ddlpHyIu2VSq5F7Xr+92SFl9l7Nmqfbr57bD11+rzpzptpeqG5QwNNTVljLurN9/38177dqsv++ICJc8AgNVP/pItWFD93zQILfeIqq9ernfSZMmqTvd3393309YWPqd/P/+5w4egoJczaRbN7f8Pn1Sy5w44RJ8u3ZuOTt3uprcU0+5bVKihDuYyMqOHam/w7S1z19/zbp8biIi3O8oZV4XXKC6Kc0w3ydOuIOP/ftzns/x46m/odzEx6u++GLmg6Hly933DarPPHNaq5GjXbtUv/8+5/iSk10tsoCxRJDRo4+6H2l2O9DYWPcPcTo/oO3b3U6qe3f348zNyZOutjF9et6XMWOGO8Lp0MHtpDt3dv80OTl+XPWrr9yOomLFzEeIQ4a4n0HGneaoUVnvcOvVU331VRfLwYPuO1y40B2JlynjytSo4Y4IQfWee9z3kZzsmrcqVnQ7+8OHU5d16JDbJi1bqrZoodq8uXveurVrhmvXzh2JX3ed6r33uiP+iRNVV6xwO7Po6PT/mHPmuG0h4sr/3/+5ppqnn3bbPav1KlrUfa8XXqhaoUL6HViK8HDVYsVUn3wy/fTkZLfzvPRS9/7kyW76kSMu5pSEOXWqm/7LL27n3qqVS3ZpE2qXLm6H+uWXLv727VOTlKrqE0+4cv/7n9uhtmrlyjVunD4pBgW577R1azftnXfS/94jI1NrgqtWud/vzJmu9lq8eGpNJu3vaPRod4BQpoxLpCm/86QkF29oqDtIePlltyMODXU1v927XW25Xj09VQNNW7NOSlIdO9YltEsucWUqV3a/qWnT3P9jVk6eVL3pptR1Tok5OdnFGRKi2rOnez/twdY//7gaZV7+T1McO+ZqncHBbn53352+dp6y3ClTVC+/3JXp1El16dLs55nyv/PYY+4317mz+12fTlynwRJBRp984lZ9ZzY3qvjtN/d+yj90XhXw+xZkKSnJ/VNkFBPjmqjeesv90w8YoLpsWc7rePKkO1rq2tXtEB58MHO1PCEhf76nY8fcjj801O2cwf298073z3bihNvhbtvm+kh693Y7wVKl0vfhZPTww67MZ5+5ndfo0alNgFWqZD6ajo9XHTYsc3/LpEnuO6pQwTVtnTypOny4S0gpR+mdOmVu4oqLc02FxYq5hFuihOrPP7v3tmxxzZj9+6cedZ886fqzwO1oBg1yO8xrrnHJYu7c9PM/eNAltOLFVSdMcAcrt96qWrKkm8eFF6YmryZN3HeQsuNr2zZ9c9Dy5S5ppCTfOnXcgUdwsKshHznimiE7dXLvh4S42uCbb6redZf7nsEdPLz4our69anzPnJE9aqrXAIYMkS1QQPXFBoZ6f5vQfXTT10N6+ab3Xf9/PPuICMlYZYq5Q5KhgxJ34e1cqX7nZQv72Ju1Sq1pnnffS4+cLXUyEiXWIYMcbU+cAchL77o1gdc82/v3q4m16ePO1js2tXVWsF9t3ff7eJP+R2FhakeOODiSU52CeWJJ7Kv3eWBJYKMNm50/3C33pr1Tum119wPJ6V92Jy+lKaxgiI2Nvsjy7Rya5JYvtztQDPWkkaMyHyEmJtNm1x/S1qLFrmj6G7dsp9feLjbQVWunPMRZ4rkZNUPPkjd0aQ80p7gkNbBg65ZK6VcrVruyDqlr0nVJZ8qVdz7lSq52l5W23v+fJcInn02tfY6Y4b7/7vsMpcIS5RwCSfj52NjXS3qjjtS+5OKF3dJMDDQzWPcOFf277/dtLvvVr3oIvdIObI+dswtC1zSGjjQHbD06uXKpdQorrnGJQ1wCeyxx1yfTJcubnssXJga27ffuuWn1IJTEuPXX6cuNzraJY0LLnDrGBTkYqxc2SXCm25yTWUp/WsJCS6J3XCDm19QkKvRpiSY4GC3Hc+QJYKspHRifvJJ5vdat1a94opzsxxT+MTGug73devcjjivnbd5lZSUexKNijqzA5VDh1wfyV9/5VwuPNw1P23YkH0sR464HV9ucWT1+R9/dAdbrVpl3QyX0YED7n+2d2/X1PfKK5lrbv37p+6UJ01K/96xY6knSWS0aZM7Ar/oIlcLCAtzR/q5+e03V3MYNMjVxs6lTZtcjbZMGZc0PvvMfd9nIadE4F9jDaWl6q7E/eUXWLjQDVENcOQIVKwIb7zhrhkwxnjHvn1wwQXuQsZzITERbroJiheHiRNPa4RhwO0TztGNdgqinMYa8t9bAonAV19B06buSty//4by5WHuXHcxV6dOvo7QmMKtatVzO7/AQJgxwz0/kx16IU4CufG/K4vTqlgRxo6FnTvhyivdkAy//gqlSrkhG4wx5xcRv96hnyn/rRGkuOoqmDULbrsN2rRxP6JrrnHDMBhjjB/w7xpBimuvhT/+gCJFXLulNQsZY/yI1QhSNGrkOo0//tgNOWyMMX7CEkFa1avnPI6/McYUQtY0ZIwxfs4SgTHG+DlLBMYY4+csERhjjJ/zaiIQkS4isklEtopInyzeLyYi4zzvLxaR2t6MxxhjTGZeSwQiUgQYBtwANATuE5GGGYp1B46oaj1gCPCBt+IxxhiTNW/WCFoDW1V1u6rGA98Dt2Qocwsw2vP8B6CjiF0fbowx+cmbiaAasDvN6z2eaVmWUdVEIBoIyTgjEekhIktFZGl4eLiXwjXGGP90XlxQpqojgBEAIhIuIjvPcFYVgcPnLLDzg62zf7B19g9ns861snvDm4lgL1AjzevqnmlZldkjIoFAWSAip5mqauiZBiQiS7Mbj7uwsnX2D7bO/sFb6+zNpqElQH0RqSMiQcC9wOQMZSYDj3ie3wn8pufbnXKMMeY857UagaomisjTwCygCPClqq4TkX64W6ZNBr4AxojIViASlyyMMcbkI6/2EajqdGB6hmlvpnkeC9zlzRgyGJGPyyoobJ39g62zf/DKOp939yw2xhhzbtkQE8YY4+csERhjjJ/zm0SQ27hHhYGI1BCRuSKyXkTWichznukVRGS2iGzx/C3v61jPJREpIiIrRGSq53Udz9hVWz1jWQX5OsZzSUTKicgPIrJRRDaISFs/2MYveH7Ta0VkrIgEF7btLCJfisghEVmbZlqW21WcTzzrvlpEmp/Nsv0iEeRx3KPCIBF4SVUbAm2Apzzr2QeYo6r1gTme14XJc8CGNK8/AIZ4xrA6ghvTqjD5GJipqhcDl+HWvdBuYxGpBjwLtFTVRrizEO+l8G3nr4EuGaZlt11vAOp7Hj2A/57Ngv0iEZC3cY/Oe6q6X1WXe54fw+0gqpF+TKfRwK0+CdALRKQ6cCMwyvNagA64saug8K1vWeBq3KnXqGq8qkZRiLexRyBQ3HPhaQlgP4VsO6vqfNxp9Gllt11vAb5RZxFQTkSqnOmy/SUR5GXco0LFM6R3M2AxUElV93veOgBU8lVcXvAR8H9Asud1CBDlGbsKCt+2rgOEA195msNGiUhJCvE2VtW9wCBgFy4BRAPLKNzbOUV22/Wc7tP8JRH4FREpBfwIPK+qR9O+57lyu1CcMywiNwGHVHWZr2PJR4FAc+C/qtoMOEGGZqDCtI0BPO3it+CSYFWgJJmbUAo9b25Xf0kEeRn3qFAQkaK4JPCtqk70TD6YUm30/D3kq/jOsXZANxHZgWvu64BrPy/naUKAwret9wB7VHWx5/UPuMRQWLcxwHXAP6oarqoJwETcti/M2zlFdtv1nO7T/CUR5GXco/Oep338C2CDqg5O81baMZ0eASbld2zeoKqvqmp1Va2N26a/qeoDwFzc2FVQiNYXQFUPALtF5CLPpI7AegrpNvbYBbQRkRKe33jKOhfa7ZxGdtt1MvCw5+yhNkB0miak06eqfvEAugKbgW3A676Ox0vreCWu6rgaWOl5dMW1m88BtgC/AhV8HasX1r09MNXz/ELgb2ArMAEo5uv4zvG6NgWWerbzz0D5wr6Ngb7ARmAtMAYoVti2MzAW1weSgKv5dc9uuwKCOxNyG7AGd0bVGS/bhpgwxhg/5y9NQ8YYY7JhicAYY/ycJQJjjPFzlgiMMcbPWSIwxhg/Z4nAmAxEJElEVqZ5nLMB3ESkdtrRJY0pCLx6q0pjzlMxqtrU10EYk1+sRmBMHonIDhEZICJrRORvEannmV5bRH7zjAs/R0RqeqZXEpGfRGSV53GFZ1ZFRGSkZ3z9X0SkuM9WyhgsERiTleIZmobuSfNetKo2BobiRj4F+BQYrapNgG+BTzzTPwHmqepluPGA1nmm1weGqeqlQBRwh1fXxphc2JXFxmQgIsdVtVQW03cAHVR1u2dwvwOqGiIih4Eqqprgmb5fVSuKSDhQXVXj0syjNjBb3Y1GEJFXgKKq+nY+rJoxWbIagTGnR7N5fjri0jxPwvrqjI9ZIjDm9NyT5u9Cz/O/cKOfAjwALPA8nwP0glP3VS6bX0EaczrsSMSYzIqLyMo0r2eqasoppOVFZDXuqP4+z7RncHcMexl397B/eaY/B4wQke64I/9euNEljSlQrI/AmDzy9BG0VNXDvo7FmHPJmoaMMcbPWY3AGGP8nNUIjDHGz1kiMMYYP2eJwBhj/JwlAmOM8XOWCIwxxs/9Pwuzg9OCf7QUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Loop, adapted from https://github.com/taesungp/contrastive-unpaired-translation\n",
    "\n",
    "prev_time = time.time()\n",
    "for epoch in range(epoch, epochs):\n",
    "    total_D_loss = 0\n",
    "    total_GAN_loss = 0\n",
    "    total_NCE_loss = 0\n",
    "    total_G_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        x, y = Variable(batch[\"a\"].type(Tensor)), Variable(batch[\"b\"].type(Tensor))\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        real = Variable(Tensor(np.ones((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "        fake = Variable(Tensor(np.zeros((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "        \n",
    "        # train discriminator\n",
    "        D.train()\n",
    "        optimizer_D.zero_grad()\n",
    "        # get the fake loss\n",
    "        fake_y = G(x)\n",
    "        D_fake = D(fake_y.detach())\n",
    "        loss_D_fake = criterion_GAN(D_fake, fake).mean()\n",
    "        # get the real loss\n",
    "        D_real = D(y)\n",
    "        loss_D_real = criterion_GAN(D_real, real).mean()\n",
    "        # combine loss and calculate gradients\n",
    "        loss_D = (loss_D_fake + loss_D_real) * 0.5\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # train generator\n",
    "        G.train()\n",
    "        optimizer_G.zero_grad()\n",
    "        optimizer_Sampler.zero_grad()\n",
    "        # get the fake GAN loss\n",
    "        D_fake = D(fake_y)\n",
    "        loss_G_GAN = criterion_GAN(D_fake, real).mean()\n",
    "        # get the NCE loss\n",
    "        Sampler.train()\n",
    "        total_nce_loss = 0\n",
    "        for fake, real in [(fake_y, x), (y, G(y))]:\n",
    "            feat_q = G(fake_y, nce_layers, encode_only = True)\n",
    "            feat_k = G(x, nce_layers, encode_only = True)\n",
    "\n",
    "            feat_k_pool, sample_ids = Sampler(feat_k, 256, None)\n",
    "            feat_q_pool, _ = Sampler(feat_q, 256, sample_ids)\n",
    "\n",
    "            total_nce_loss = 0.0\n",
    "            for f_q, f_k, crit, nce_layer in zip(feat_q_pool, feat_k_pool, criterion_NCE, nce_layers):\n",
    "                loss = crit(f_q, f_k) * lambda_NCE\n",
    "                total_nce_loss += loss.mean()\n",
    "\n",
    "            nce_loss = total_nce_loss / len(nce_layers)\n",
    "            total_nce_loss += nce_loss\n",
    "        total_nce_loss *= 0.5\n",
    "        \n",
    "        loss_G = loss_G_GAN + total_nce_loss\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        optimizer_Sampler.step()\n",
    "        \n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        # Determine approximate time left\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        batches_left = epochs * len(dataloader) - batches_done\n",
    "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "        prev_time = time.time()\n",
    "\n",
    "        # Print log\n",
    "        sys.stdout.write(\n",
    "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [GAN loss: %f, NCE loss: %f, Total: %f] ETA: %s\"\n",
    "            % (\n",
    "                epoch,\n",
    "                epochs,\n",
    "                i,\n",
    "                len(dataloader),\n",
    "                loss_D.item(),\n",
    "                loss_G_GAN.item(),\n",
    "                nce_loss.item(),\n",
    "                loss_G.item(),\n",
    "                time_left,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        total_D_loss += loss_D.item()\n",
    "        total_GAN_loss += loss_G_GAN.item()\n",
    "        total_NCE_loss += nce_loss.item()\n",
    "        total_G_loss += loss_G.item()\n",
    "        \n",
    "        # If at sample interval save image\n",
    "        if batches_done % 300 == 0:\n",
    "            sample_images(batches_done)\n",
    "            \n",
    "    D_losses.append(total_D_loss / len(dataloader))\n",
    "    GAN_losses.append(total_GAN_loss / len(dataloader))\n",
    "    NCE_losses.append(total_NCE_loss / len(dataloader))\n",
    "    G_total_losses.append(total_G_loss / len(dataloader))\n",
    "    display.clear_output(wait = True)\n",
    "    time.sleep(1)\n",
    "    plt.clf()\n",
    "    plt.ylabel('Mean Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.plot(D_losses, color = 'r')\n",
    "    plt.plot(GAN_losses, color = 'g')\n",
    "    plt.plot(NCE_losses, color = 'b')\n",
    "    plt.savefig('models/%s/loss_plot.png' % model_name)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "    if not os.path.isdir('models'):\n",
    "        os.makedirs('models')\n",
    "    if not os.path.isdir('models/%s' % model_name):\n",
    "        os.makedirs('models/%s' % model_name)\n",
    "    torch.save(G.state_dict(), \"models/%s/G_%d.pth\" % (model_name, epoch))\n",
    "    torch.save(D.state_dict(), \"models/%s/D_%d.pth\" % (model_name, epoch))\n",
    "    torch.save(Sampler.state_dict(), \"models/%s/Sampler_%d.pth\" % (model_name, epoch))\n",
    "    np.save('models/%s/losses_%d.npy' % (model_name, epoch), np.array([D_losses, GAN_losses, NCE_losses, G_total_losses]))\n",
    "    try:\n",
    "        os.remove('models/%s/G_%d.pth' % (model_name, epoch - 1))\n",
    "        os.remove('models/%s/D_%d.pth' % (model_name, epoch - 1))\n",
    "        os.remove('models/%s/Sampler_%d.pth' % (model_name, epoch - 1))\n",
    "        os.remove('models/%s/losses_%d.npy' % (model_name, epoch - 1))\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Generator:\n\tsize mismatch for model.1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 3, 5, 5]).\n\tsize mismatch for model.28.weight: copying a param with shape torch.Size([3, 64, 7, 7]) from checkpoint, the shape in current model is torch.Size([3, 64, 5, 5]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-87edf3e372c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mG_compare\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mG_compare\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/%s%s/G_%d.pth'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_e\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mG_compare\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1052\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1053\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Generator:\n\tsize mismatch for model.1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 3, 5, 5]).\n\tsize mismatch for model.28.weight: copying a param with shape torch.Size([3, 64, 7, 7]) from checkpoint, the shape in current model is torch.Size([3, 64, 5, 5])."
     ]
    }
   ],
   "source": [
    "imgs = next(iter(val_dataloader))\n",
    "real_A = Variable(imgs[\"a\"].type(Tensor)).detach()\n",
    "\n",
    "values = ['init-conv5', 'lr2e-3']\n",
    "dir_name = 'G2M-frames-'\n",
    "total_e = 99\n",
    "output_dir = 'G2M-init-conv'\n",
    "\n",
    "for n in values:\n",
    "    G_compare = Generator(input_size, 9, kernel_size).to(device)\n",
    "    G_compare.load_state_dict(torch.load('models/%s%s/G_%d.pth' % (dir_name, n, total_e)))\n",
    "    G_compare.eval()\n",
    "    \n",
    "    fake_B = G_compare(real_A.detach())\n",
    "    # Arange images along x-axis\n",
    "    real_A_grid = make_grid(real_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    # Arange images along y-axis\n",
    "    image_grid = torch.cat((real_A_grid, fake_B), 1)\n",
    "    if not os.path.isdir('comparisons/%s' % output_dir):\n",
    "        os.makedirs('comparisons/%s' % output_dir)\n",
    "    save_image(image_grid, \"comparisons/%s/%s.png\" % (output_dir, n), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
