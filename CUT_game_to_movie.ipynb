{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.19.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.4.0.46)\n",
      "Requirement already satisfied: dlib in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (19.21.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: boto3 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.17.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3) (0.3.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.4 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from boto3) (1.20.4)\n",
      "Requirement already satisfied: six in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from botocore<1.21.0,>=1.20.4->boto3) (1.26.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy opencv-python dlib matplotlib boto3\n",
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    !pip install pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time, datetime, sys\n",
    "import zipfile as zf\n",
    "import boto3\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import dlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model name - determines where the outputs are saved\n",
    "model_name = 'G2M-frames-lr2e-3'\n",
    "\n",
    "# Variables/Hyperparameters\n",
    "dataset_size = 600\n",
    "generate_dataset = True\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "nce_layers = [0, 4, 8, 12, 16]\n",
    "lambda_NCE = 1.0\n",
    "lambda_GAN = 1.0\n",
    "batch_size = 1\n",
    "load_weights = True\n",
    "epoch = 0\n",
    "epochs = 100\n",
    "nonsaturating = False\n",
    "\n",
    "\n",
    "res_blocks = 9 # def = 9\n",
    "learning_rate = 0.002\n",
    "kernel_size = 3\n",
    "init_kernel_size = 3\n",
    "\n",
    "D_losses = []\n",
    "GAN_losses = []\n",
    "NCE_losses = []\n",
    "G_total_losses = []\n",
    "\n",
    "# Swap the game and movie datasets, so that translation goes from movie to game instead\n",
    "swap = False\n",
    "\n",
    "# Toggle whether translation is done only on faces\n",
    "faces = True\n",
    "\n",
    "if faces:\n",
    "    input_size = (3,180,180)\n",
    "else:\n",
    "    input_size = (3,144,256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original data (and the processed data)\n",
    "s3 = boto3.resource('s3', aws_access_key_id = 'AKIAIOPFTDXA3ZXLK5YA', aws_secret_access_key = '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')\n",
    "bucket = s3.Bucket('vision-dataset-vmrj42')\n",
    "\n",
    "for fname in ['Data.zip', 'datasets.zip']:\n",
    "    if not os.path.isfile(fname):\n",
    "        bucket.download_file(fname, fname)\n",
    "\n",
    "if not os.path.isdir('Data'):\n",
    "    files = zf.ZipFile('Data.zip', 'r')\n",
    "    files.extractall('')\n",
    "if not os.path.isdir('dataset') and not generate_dataset:\n",
    "    files = zf.ZipFile('datasets.zip', 'r')\n",
    "    files.extractall('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a basic dataset for full-frame translation\n",
    "\n",
    "for dname in ['dataset/train/game', \n",
    "              'dataset/train/movie', \n",
    "              'dataset/test/game', \n",
    "              'dataset/test/movie', \n",
    "              'face_dataset/train/game',\n",
    "              'face_dataset/train/movie',\n",
    "              'face_dataset/test/game',\n",
    "              'face_dataset/test/movie']:\n",
    "    if not os.path.isdir(dname):\n",
    "        os.makedirs(dname)\n",
    "\n",
    "if len(os.listdir('dataset/train/game')) < dataset_size:\n",
    "    # get some frames from the game footage\n",
    "    cap = cv2.VideoCapture('Data/game/MafiaVideogame.mp4')\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_count = 0\n",
    "    saved_frames = 0\n",
    "    \n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    faces = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        # Save the entire frame as part of the dataset, alternating between the training and testing datasets\n",
    "        if frame_count % (length // (2 * dataset_size)) == 0 and ret:\n",
    "            if saved_frames < dataset_size:\n",
    "                fname = 'dataset/train/game/%d.png' % (saved_frames)\n",
    "            else:\n",
    "                fname = 'dataset/test/game/%d.png' % (saved_frames % dataset_size)\n",
    "            cv2.imwrite(fname, frame)\n",
    "            saved_frames += 1\n",
    "        \n",
    "        # Check if there is a face in every (length // (10 * dataset_size)) frame\n",
    "        if frame_count % (length // (6 * dataset_size)) == 0 and ret:\n",
    "            dets = face_detector(frame, 1)\n",
    "            for i, d in enumerate(dets):\n",
    "                left, top, right, bottom = d.left(), d.top(), d.right(), d.bottom()\n",
    "                if right - left > 60:\n",
    "                    face = frame[top:bottom, left:right]\n",
    "                    if len(face) > 0 and len(face[0]) > 0:\n",
    "                        faces.append(face)\n",
    "    cap.release()\n",
    "    \n",
    "    # Alternating between the training and testing datasets, save the extracted faces\n",
    "    saved_faces = 0\n",
    "    for i, face in enumerate(faces):\n",
    "        if i % (len(faces) // (2 * dataset_size)) == 0:\n",
    "            if saved_faces < dataset_size:\n",
    "                fname = 'face_dataset/train/game/%d.png' % (saved_faces)\n",
    "            else:\n",
    "                fname = 'face_dataset/test/game/%d.png' % (saved_faces % dataset_size)\n",
    "            cv2.imwrite(fname, cv2.resize(face, (input_size[1], input_size[1])))\n",
    "            saved_faces += 1\n",
    "\n",
    "    # get some frames from the movie footage\n",
    "    movie_dirs = ['Data/movie/TheGodfather.mp4', 'Data/movie/TheIrishman.mp4', 'Data/movie/TheSopranos.mp4']\n",
    "\n",
    "    saved_frames = 0\n",
    "    for movie in movie_dirs:\n",
    "        cap = cv2.VideoCapture(movie)\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_count += 1\n",
    "            if frame_count % (length // (2 * dataset_size / len(movie_dirs))) == 0 and ret:\n",
    "                if saved_frames < dataset_size:\n",
    "                    fname = 'dataset/train/movie/%d.png' % (saved_frames)\n",
    "                else:\n",
    "                    fname = 'dataset/test/movie/%d.png' % (saved_frames % dataset_size)\n",
    "                cv2.imwrite(fname, frame)\n",
    "                saved_frames += 1\n",
    "\n",
    "\n",
    "        cap.release()\n",
    "        \n",
    "    face_detector = dlib.get_frontal_face_detector()        \n",
    "    faces_dir = 'Data/faces/'\n",
    "    real_faces = os.listdir(faces_dir)\n",
    "    saved_faces = 0\n",
    "    current_face = 0\n",
    "    while saved_faces < dataset_size * 4:\n",
    "        real_face = cv2.imread(faces_dir + real_faces[current_face])\n",
    "        face = []\n",
    "        dets = face_detector(real_face, 1)\n",
    "        for d in dets:\n",
    "            left, top, right, bottom = d.left(), d.top(), d.right(), d.bottom()\n",
    "            if right - left > 20:\n",
    "                face = real_face[top : bottom, left : right]\n",
    "                if len(face) > 0 and len(face[0]) > 0:\n",
    "                    face = cv2.resize(face, (input_size[1], input_size[1]))\n",
    "                    if saved_faces < dataset_size * 2:\n",
    "                        fname = 'face_dataset/train/movie/%d.png' % (saved_faces)\n",
    "                    else:\n",
    "                        fname = 'face_dataset/test/movie/%d.png' % (saved_faces % (dataset_size * 2))\n",
    "                    cv2.imwrite(fname, face)\n",
    "                    saved_faces += 1\n",
    "                    break\n",
    "        current_face += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful class for loading both game and movie samples as one dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, swap = False, transforms_ = None, unaligned = False, mode = \"train\"):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "        if swap:\n",
    "            self.files_game = sorted(glob.glob(os.path.join(root, \"%s/movie\" % mode) + \"/*.*\"))\n",
    "            self.files_movie = sorted(glob.glob(os.path.join(root, \"%s/game\" % mode) + \"/*.*\"))\n",
    "        else:\n",
    "            self.files_game = sorted(glob.glob(os.path.join(root, \"%s/game\" % mode) + \"/*.*\"))\n",
    "            self.files_movie = sorted(glob.glob(os.path.join(root, \"%s/movie\" % mode) + \"/*.*\"))\n",
    "        print(len(os.listdir(os.path.join(root, 'train/movie'))))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_game = Image.open(self.files_game[index % len(self.files_game)])\n",
    "\n",
    "        if self.unaligned:\n",
    "            image_movie = Image.open(self.files_movie[random.randint(0, len(self.files_movie) - 1)])\n",
    "        else:\n",
    "            image_movie = Image.open(self.files_movie[index % len(self.files_movie)])\n",
    "\n",
    "        # Convert grayscale images to rgb\n",
    "        if image_game.mode != \"RGB\":\n",
    "            image_game = to_rgb(image_game)\n",
    "        if image_movie.mode != \"RGB\":\n",
    "            image_movie = to_rgb(image_movie)\n",
    "\n",
    "        item_game = self.transform(image_game)\n",
    "        item_movie = self.transform(image_movie)\n",
    "        \n",
    "        return {\"a\": item_game, \"b\": item_movie}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_game), len(self.files_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n",
      "torch.Size([5, 3, 180, 180])\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# Define the dataset-wide transformations\n",
    "\n",
    "if not faces:\n",
    "    transforms_ = [\n",
    "        transforms.Resize(int(input_size[1] * 2)),\n",
    "        transforms.RandomCrop((input_size[1], input_size[2])),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    "else:\n",
    "    transforms_ = [\n",
    "        transforms.Resize(int(input_size[1] * 1.4)),\n",
    "        transforms.RandomCrop((input_size[1], input_size[2])),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomRotation(180),\n",
    "        #transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    "\n",
    "\n",
    "if faces:\n",
    "    dataset_dir = 'face_dataset'\n",
    "else:\n",
    "    dataset_dir = 'dataset'\n",
    "# Training data loader\n",
    "dataloader = DataLoader(\n",
    "    ImageDataset(dataset_dir, swap = swap, transforms_ = transforms_, unaligned = True),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 0,\n",
    ")\n",
    "# Test data loader\n",
    "val_dataloader = DataLoader(\n",
    "    ImageDataset(dataset_dir, swap = swap, transforms_ = transforms_, unaligned = True, mode = 'test'),\n",
    "    batch_size = 5,\n",
    "    shuffle = True,\n",
    "    num_workers = 0,\n",
    ")\n",
    "\n",
    "imgs = next(iter(val_dataloader))\n",
    "print(imgs['a'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Utils\n",
    "\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.5/0.5, -0.5/0.5, -0.5/0.5],\n",
    "    std=[1/0.5, 1/0.5, 1/0.5]\n",
    ")\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if hasattr(m, \"bias\") and m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "        \n",
    "def sample_images(batches_done):\n",
    "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
    "    imgs = next(iter(val_dataloader))\n",
    "    G.eval()\n",
    "    real_A = Variable(imgs[\"a\"].type(Tensor))\n",
    "    fake_B = G(real_A)\n",
    "    for img in fake_B:\n",
    "        img = inv_normalize(img)\n",
    "    # Arange images along x-axis\n",
    "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    # Arange images along y-axis\n",
    "    image_grid = torch.cat((real_A, fake_B), 1)\n",
    "    if not os.path.isdir('models/%s/samples' % model_name):\n",
    "        os.makedirs('models/%s/samples' % model_name)\n",
    "    save_image(image_grid, \"models/%s/samples/%s.png\" % (model_name, batches_done), normalize=False)\n",
    "    \n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, power=2):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.power = power\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = x.pow(self.power).sum(1, keepdim=True).pow(1. / self.power)\n",
    "        out = x.div(norm + 1e-7)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator and Discriminator models adapted from https://github.com/eriklindernoren/PyTorch-GAN\n",
    "# PatchSampleF adapted from https://github.com/taesungp/contrastive-unpaired-translation\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features, kernel):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(kernel // 2),\n",
    "            nn.Conv2d(in_features, in_features, kernel),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(kernel // 2),\n",
    "            nn.Conv2d(in_features, in_features, kernel),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_shape, num_residual_blocks, kernel, init_kernel):\n",
    "        super(Generator, self).__init__()\n",
    "        channels = input_shape[0]\n",
    "\n",
    "        # Initial convolution block\n",
    "        out_features = 64\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(init_kernel // 2),\n",
    "            nn.Conv2d(channels, out_features, init_kernel),\n",
    "            nn.InstanceNorm2d(out_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        in_features = out_features\n",
    "\n",
    "        # Downsampling\n",
    "        for _ in range(2):\n",
    "            out_features *= 2\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel, stride=2, padding=kernel//2),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            in_features = out_features\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(num_residual_blocks):\n",
    "            model += [ResidualBlock(out_features, kernel)]\n",
    "\n",
    "        # Upsampling\n",
    "        for _ in range(2):\n",
    "            out_features //= 2\n",
    "            model += [\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(in_features, out_features, kernel, stride=1, padding=kernel//2),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            in_features = out_features\n",
    "\n",
    "        # Output layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(init_kernel // 2), \n",
    "            nn.Conv2d(out_features, channels, init_kernel), \n",
    "            nn.Tanh()\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x, layers = [], encode_only = False):\n",
    "        if -1 in layers:\n",
    "            layers.append(len(self.model))\n",
    "        if len(layers) > 0:\n",
    "            feat = x\n",
    "            feats = []\n",
    "            for layer_id, layer in enumerate(self.model):\n",
    "                feat = layer(feat)\n",
    "                if layer_id in layers:\n",
    "                    feats.append(feat)\n",
    "                else:\n",
    "                    pass\n",
    "                if layer_id == layers[-1] and encode_only:\n",
    "                    return feats\n",
    "            return feat, feats\n",
    "        else:\n",
    "            return self.model(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        channels, height, width = input_shape\n",
    "        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalize = True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 64, normalize=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n",
    "    \n",
    "class PatchSampleF(nn.Module):\n",
    "    def __init__(self, use_mlp = True, init_type = 'normal', init_gain = 0.02, nc = 256):\n",
    "        # potential issues: currently, we use the same patch_ids for multiple images in the batch\n",
    "        super(PatchSampleF, self).__init__()\n",
    "        self.l2norm = Normalize(2)\n",
    "        self.use_mlp = use_mlp\n",
    "        self.nc = nc  # hard-coded\n",
    "        self.mlp_init = False\n",
    "        self.init_type = init_type\n",
    "        self.init_gain = init_gain\n",
    "\n",
    "    def create_mlp(self, feats):\n",
    "        for mlp_id, feat in enumerate(feats):\n",
    "            input_nc = feat.shape[1]\n",
    "            mlp = nn.Sequential(*[nn.Linear(input_nc, self.nc), nn.ReLU(), nn.Linear(self.nc, self.nc)])\n",
    "            if torch.cuda.is_available():\n",
    "                mlp.cuda()\n",
    "            setattr(self, 'mlp_%d' % mlp_id, mlp)\n",
    "        if torch.cuda.is_available():\n",
    "            self.to(device)\n",
    "        self.apply(weights_init_normal)\n",
    "        self.mlp_init = True\n",
    "\n",
    "    def forward(self, feats, num_patches = 64, patch_ids = None):\n",
    "        return_ids = []\n",
    "        return_feats = []\n",
    "        if self.use_mlp and not self.mlp_init:\n",
    "            self.create_mlp(feats)\n",
    "        for feat_id, feat in enumerate(feats):\n",
    "            B, H, W = feat.shape[0], feat.shape[2], feat.shape[3]\n",
    "            feat_reshape = feat.permute(0, 2, 3, 1).flatten(1, 2)\n",
    "            if num_patches > 0:\n",
    "                if patch_ids is not None:\n",
    "                    patch_id = patch_ids[feat_id]\n",
    "                else:\n",
    "                    patch_id = torch.randperm(feat_reshape.shape[1], device=feats[0].device)\n",
    "                    patch_id = patch_id[:int(min(num_patches, patch_id.shape[0]))]  # .to(patch_ids.device)\n",
    "                x_sample = feat_reshape[:, patch_id, :].flatten(0, 1)  # reshape(-1, x.shape[1])\n",
    "            else:\n",
    "                x_sample = feat_reshape\n",
    "                patch_id = []\n",
    "            if self.use_mlp:\n",
    "                mlp = getattr(self, 'mlp_%d' % feat_id)\n",
    "                x_sample = mlp(x_sample)\n",
    "            return_ids.append(patch_id)\n",
    "            x_sample = self.l2norm(x_sample)\n",
    "\n",
    "            if num_patches == 0:\n",
    "                x_sample = x_sample.permute(0, 2, 1).reshape([B, x_sample.shape[-1], H, W])\n",
    "            return_feats.append(x_sample)\n",
    "        return return_feats, return_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to create separate losses for each feature, from https://github.com/taesungp/contrastive-unpaired-translation\n",
    "class PatchNCELoss(nn.Module):\n",
    "    def __init__(self, batch_size, nce_T = 0.07):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.nce_T = nce_T\n",
    "        self.cross_entropy_loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        self.mask_dtype = torch.bool\n",
    "\n",
    "    def forward(self, feat_q, feat_k):\n",
    "        batchSize = feat_q.shape[0]\n",
    "        dim = feat_q.shape[1]\n",
    "        feat_k = feat_k.detach()\n",
    "\n",
    "        # pos logit\n",
    "        l_pos = torch.bmm(feat_q.view(batchSize, 1, -1), feat_k.view(batchSize, -1, 1))\n",
    "        l_pos = l_pos.view(batchSize, 1)\n",
    "\n",
    "        batch_dim_for_bmm = self.batch_size\n",
    "\n",
    "        # reshape features to batch size\n",
    "        feat_q = feat_q.view(batch_dim_for_bmm, -1, dim)\n",
    "        feat_k = feat_k.view(batch_dim_for_bmm, -1, dim)\n",
    "        npatches = feat_q.size(1)\n",
    "        l_neg_curbatch = torch.bmm(feat_q, feat_k.transpose(2, 1))\n",
    "\n",
    "        # diagonal entries are similarity between same features, and hence meaningless.\n",
    "        # just fill the diagonal with very small number, which is exp(-10) and almost zero\n",
    "        diagonal = torch.eye(npatches, device=feat_q.device, dtype=self.mask_dtype)[None, :, :]\n",
    "        l_neg_curbatch.masked_fill_(diagonal, -10.0)\n",
    "        l_neg = l_neg_curbatch.view(-1, npatches)\n",
    "\n",
    "        out = torch.cat((l_pos, l_neg), dim=1) / self.nce_T\n",
    "\n",
    "        loss = self.cross_entropy_loss(out, torch.zeros(out.size(0), dtype=torch.long,\n",
    "                                                        device=feat_q.device))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "def nonsaturating_loss(prediction, is_real):\n",
    "    if is_real.mean() == 1:\n",
    "        loss = F.softplus(-prediction).view(prediction.size(0), -1).mean(dim = 1)\n",
    "    else:\n",
    "        loss = F.softplus(prediction).view(prediction.size(0), -1).mean(dim = 1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the networks, load the most recent saved models, and set the loss functions and optimizers\n",
    "\n",
    "if faces:\n",
    "    input_size = (input_size[0], input_size[1], input_size[1])\n",
    "G = Generator(input_size, res_blocks, kernel_size, init_kernel_size).to(device)\n",
    "D = Discriminator(input_size).to(device)\n",
    "Sampler = PatchSampleF(batch_size).to(device)\n",
    "\n",
    "if nonsaturating:\n",
    "    criterion_GAN = nonsaturating_loss\n",
    "else:\n",
    "    criterion_GAN = torch.nn.MSELoss().to(device)\n",
    "criterion_NCE = []\n",
    "\n",
    "for nce_layer in nce_layers:\n",
    "    criterion_NCE.append(PatchNCELoss(batch_size).to(device))\n",
    "\n",
    "G.apply(weights_init_normal)\n",
    "D.apply(weights_init_normal)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr = learning_rate)\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the sampler are not made until the first forward pass through the Sampler network\n",
    "# Hence, we do a 'trial' training pass before setting the optimizer for the Sampler\n",
    "for i, batch in enumerate(dataloader):\n",
    "    x, y = Variable(batch[\"a\"].type(Tensor)), Variable(batch[\"b\"].type(Tensor))\n",
    "    \n",
    "    real = Variable(Tensor(np.ones((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "    fake = Variable(Tensor(np.zeros((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "    \n",
    "    D.eval()\n",
    "    G.eval()\n",
    "    Sampler.eval()\n",
    "    # get the fake loss\n",
    "    fake_y = G(x)\n",
    "    D_fake = D(fake_y.detach())\n",
    "    loss_D_fake = criterion_GAN(D_fake, fake).mean()\n",
    "    # get the real loss\n",
    "    D_real = D(y)\n",
    "    loss_D_real = criterion_GAN(D_real, real).mean()\n",
    "    # combine loss and calculate gradients\n",
    "    loss_D = (loss_D_fake + loss_D_real) * 0.5\n",
    "    loss_D.backward()\n",
    "\n",
    "    # get the fake GAN loss\n",
    "    D_fake = D(fake_y)\n",
    "    loss_G_GAN = lambda_GAN * criterion_GAN(D_fake, real).mean()\n",
    "    total_nce_loss = 0\n",
    "    for fake, real in [(fake_y, x), (y, G(y))]:\n",
    "        # get the NCE loss\n",
    "        feat_q = G(fake, nce_layers, encode_only = True)\n",
    "        feat_k = G(real, nce_layers, encode_only = True)\n",
    "\n",
    "        feat_k_pool, sample_ids = Sampler(feat_k, 256, None)\n",
    "        feat_q_pool, _ = Sampler(feat_q, 256, sample_ids)\n",
    "\n",
    "        total_nce_loss = 0.0\n",
    "        for f_q, f_k, crit, nce_layer in zip(feat_q_pool, feat_k_pool, criterion_NCE, nce_layers):\n",
    "            loss = crit(f_q, f_k) * lambda_NCE\n",
    "            total_nce_loss += loss.mean()\n",
    "\n",
    "        nce_loss = total_nce_loss / len(nce_layers)\n",
    "        total_nce_loss += nce_loss\n",
    "\n",
    "    loss_G = loss_G_GAN + total_nce_loss\n",
    "    loss_G.backward()\n",
    "    \n",
    "    break\n",
    "\n",
    "optimizer_Sampler = torch.optim.Adam(Sampler.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the most recently saved models if available\n",
    "if os.path.isdir('models/%s' % model_name) and load_weights:\n",
    "    # Get the most recent model and load them\n",
    "    epoch = max([int(fname[8:-4]) for fname in os.listdir('models/%s' % model_name) if 'Sampler' in fname])\n",
    "    G.load_state_dict(torch.load('models/%s/G_%d.pth' % (model_name, epoch)))\n",
    "    D.load_state_dict(torch.load('models/%s/D_%d.pth' % (model_name, epoch)))\n",
    "    Sampler.load_state_dict(torch.load('models/%s/Sampler_%d.pth' % (model_name, epoch)))\n",
    "    # Load the losses as well, for plotting\n",
    "    losses = np.load('models/%s/losses_%d.npy' % (model_name, epoch))\n",
    "    D_losses = list(losses[0])\n",
    "    GAN_losses = list(losses[1])\n",
    "    NCE_losses = list(losses[2])\n",
    "    G_total_losses = list(losses[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Loop, adapted from https://github.com/taesungp/contrastive-unpaired-translation\n",
    "\n",
    "prev_time = time.time()\n",
    "for epoch in range(epoch, epochs):\n",
    "    total_D_loss = 0\n",
    "    total_GAN_loss = 0\n",
    "    total_NCE_loss = 0\n",
    "    total_G_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        x, y = Variable(batch[\"a\"].type(Tensor)), Variable(batch[\"b\"].type(Tensor))\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        real = Variable(Tensor(np.ones((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "        fake = Variable(Tensor(np.zeros((x.size(0), *D.output_shape))), requires_grad = False)\n",
    "        \n",
    "        # train discriminator\n",
    "        D.train()\n",
    "        optimizer_D.zero_grad()\n",
    "        # get the fake loss\n",
    "        fake_y = G(x)\n",
    "        D_fake = D(fake_y.detach())\n",
    "        loss_D_fake = criterion_GAN(D_fake, fake).mean()\n",
    "        # get the real loss\n",
    "        D_real = D(y)\n",
    "        loss_D_real = criterion_GAN(D_real, real).mean()\n",
    "        # combine loss and calculate gradients\n",
    "        loss_D = (loss_D_fake + loss_D_real) * 0.5\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # train generator\n",
    "        G.train()\n",
    "        optimizer_G.zero_grad()\n",
    "        optimizer_Sampler.zero_grad()\n",
    "        # get the fake GAN loss\n",
    "        D_fake = D(fake_y)\n",
    "        loss_G_GAN = criterion_GAN(D_fake, real).mean()\n",
    "        # get the NCE loss\n",
    "        Sampler.train()\n",
    "        total_nce_loss = 0\n",
    "        for fake, real in [(fake_y, x), (y, G(y))]:\n",
    "            feat_q = G(fake_y, nce_layers, encode_only = True)\n",
    "            feat_k = G(x, nce_layers, encode_only = True)\n",
    "\n",
    "            feat_k_pool, sample_ids = Sampler(feat_k, 256, None)\n",
    "            feat_q_pool, _ = Sampler(feat_q, 256, sample_ids)\n",
    "\n",
    "            total_nce_loss = 0.0\n",
    "            for f_q, f_k, crit, nce_layer in zip(feat_q_pool, feat_k_pool, criterion_NCE, nce_layers):\n",
    "                loss = crit(f_q, f_k) * lambda_NCE\n",
    "                total_nce_loss += loss.mean()\n",
    "\n",
    "            nce_loss = total_nce_loss / len(nce_layers)\n",
    "            total_nce_loss += nce_loss\n",
    "        total_nce_loss *= 0.5\n",
    "        \n",
    "        loss_G = loss_G_GAN + total_nce_loss\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        optimizer_Sampler.step()\n",
    "        \n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        # Determine approximate time left\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        batches_left = epochs * len(dataloader) - batches_done\n",
    "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "        prev_time = time.time()\n",
    "\n",
    "        # Print log\n",
    "        sys.stdout.write(\n",
    "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [GAN loss: %f, NCE loss: %f, Total: %f] ETA: %s\"\n",
    "            % (\n",
    "                epoch,\n",
    "                epochs,\n",
    "                i,\n",
    "                len(dataloader),\n",
    "                loss_D.item(),\n",
    "                loss_G_GAN.item(),\n",
    "                nce_loss.item(),\n",
    "                loss_G.item(),\n",
    "                time_left,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        total_D_loss += loss_D.item()\n",
    "        total_GAN_loss += loss_G_GAN.item()\n",
    "        total_NCE_loss += nce_loss.item()\n",
    "        total_G_loss += loss_G.item()\n",
    "        \n",
    "        # If at sample interval save image\n",
    "        if batches_done % 300 == 0:\n",
    "            sample_images(batches_done)\n",
    "            \n",
    "    D_losses.append(total_D_loss / len(dataloader))\n",
    "    GAN_losses.append(total_GAN_loss / len(dataloader))\n",
    "    NCE_losses.append(total_NCE_loss / len(dataloader))\n",
    "    G_total_losses.append(total_G_loss / len(dataloader))\n",
    "    display.clear_output(wait = True)\n",
    "    time.sleep(1)\n",
    "    plt.clf()\n",
    "    plt.ylabel('Mean Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.plot(D_losses, color = 'r')\n",
    "    plt.plot(GAN_losses, color = 'g')\n",
    "    plt.plot(NCE_losses, color = 'b')\n",
    "    plt.savefig('models/%s/loss_plot.png' % model_name)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "    if not os.path.isdir('models'):\n",
    "        os.makedirs('models')\n",
    "    if not os.path.isdir('models/%s' % model_name):\n",
    "        os.makedirs('models/%s' % model_name)\n",
    "    torch.save(G.state_dict(), \"models/%s/G_%d.pth\" % (model_name, epoch))\n",
    "    torch.save(D.state_dict(), \"models/%s/D_%d.pth\" % (model_name, epoch))\n",
    "    torch.save(Sampler.state_dict(), \"models/%s/Sampler_%d.pth\" % (model_name, epoch))\n",
    "    np.save('models/%s/losses_%d.npy' % (model_name, epoch), np.array([D_losses, GAN_losses, NCE_losses, G_total_losses]))\n",
    "    try:\n",
    "        os.remove('models/%s/G_%d.pth' % (model_name, epoch - 1))\n",
    "        os.remove('models/%s/D_%d.pth' % (model_name, epoch - 1))\n",
    "        os.remove('models/%s/Sampler_%d.pth' % (model_name, epoch - 1))\n",
    "        os.remove('models/%s/losses_%d.npy' % (model_name, epoch - 1))\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = next(iter(val_dataloader))\n",
    "\n",
    "values = [3, 5, 7]\n",
    "dir_name = 'G2M-faces-conv'\n",
    "total_e = 99\n",
    "output_dir = 'G2M-faces-conv'\n",
    "\n",
    "for n in values:\n",
    "    G_compare = Generator(input_size, 9, n, 3).to(device)\n",
    "    G_compare.load_state_dict(torch.load('models/%s%d/G_%d.pth' % (dir_name, n, total_e)))\n",
    "    G_compare.eval()\n",
    "    \n",
    "    real_A = Variable(imgs[\"a\"].type(Tensor)).detach()\n",
    "    fake_B = G_compare(real_A)\n",
    "    for img in fake_B:\n",
    "        img = inv_normalize(img)\n",
    "    \n",
    "    # Arange images along x-axis\n",
    "    real_A_grid = make_grid(real_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    \n",
    "    # Arange images along y-axis\n",
    "    image_grid = torch.cat((real_A_grid, fake_B), 1)\n",
    "    if not os.path.isdir('comparisons/%s' % output_dir):\n",
    "        os.makedirs('comparisons/%s' % output_dir)\n",
    "    save_image(image_grid, \"comparisons/%s/%d.png\" % (output_dir, n), normalize=False)\n",
    "    \n",
    "    \n",
    "def sample_images(batches_done):\n",
    "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
    "    imgs = next(iter(val_dataloader))\n",
    "    G.eval()\n",
    "    real_A = Variable(imgs[\"a\"].type(Tensor))\n",
    "    fake_B = G(real_A)\n",
    "    for img in fake_B:\n",
    "        img = inv_normalize(img)\n",
    "    # Arange images along x-axis\n",
    "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    # Arange images along y-axis\n",
    "    image_grid = torch.cat((real_A, fake_B), 1)\n",
    "    if not os.path.isdir('models/%s/samples' % model_name):\n",
    "        os.makedirs('models/%s/samples' % model_name)\n",
    "    save_image(image_grid, \"models/%s/samples/%s.png\" % (model_name, batches_done), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game footage is 30 fps\n",
    "video_length = 30 * 30\n",
    "frames_model = 'G2M-frames-lr2e-3'\n",
    "faces_model = 'G2M-faces-lr2e-3'\n",
    "total_e = 99\n",
    "output_name = 'test-clip'\n",
    "\n",
    "frame_transforms = transforms.Compose([\n",
    "    transforms.Resize(144),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "face_transforms = transforms.Compose([\n",
    "    transforms.Resize(180),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "frame_upsample = transforms.Compose([\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((576, 1024)), \n",
    "    #transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "cap = cv2.VideoCapture('Data/game/MafiaVideogame.mp4')\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "start = random.randrange((length - video_length)//10)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "if not os.path.isdir('output_movies'):\n",
    "    os.mkdir('output_movies')\n",
    "output = cv2.VideoWriter('output_movies/%s.mp4' % output_name, fourcc, 30, (1024, 576))\n",
    "\n",
    "G_frames = Generator((3,144,256), 9, 3, 3).to(device)\n",
    "G_frames.load_state_dict(torch.load('models/%s/G_%d.pth' % (frames_model, total_e)))\n",
    "G_frames.eval()\n",
    "\n",
    "G_faces = Generator((3,180,180), 9, 5, 7).to(device)\n",
    "G_faces.load_state_dict(torch.load('models/%s/G_%d.pth' % (faces_model, total_e)))\n",
    "G_faces.eval()\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "    # Save the entire frame as part of the dataset, alternating between the training and testing datasets\n",
    "    if frame_count >= start and frame_count < start + video_length and ret:\n",
    "        output_frame = np.zeros((576,1024,3))\n",
    "        \n",
    "        quadrants = [frame[:720//2, :1280//2], frame[720//2:, :1280//2], frame[:720//2, 1280//2:], frame[720//2:, 1280//2:]]\n",
    "        quadrants = [Image.fromarray(q, 'RGB') for q in quadrants]\n",
    "        inputs = torch.stack([frame_transforms(q) for q in quadrants], dim = 0).to(device)\n",
    "        frame_outputs = G_frames(inputs).detach()\n",
    "        output_frame = torch.cat((torch.cat((frame_outputs[0], frame_outputs[1]), 1), torch.cat((frame_outputs[2], frame_outputs[3]), 1)), 2)\n",
    "        output_frame = frame_upsample(output_frame)\n",
    "        #output_frame = np.array(output_frame)\n",
    "        #output_frame = output_frame.cpu().numpy().transpose(1,2,0)\n",
    "        \n",
    "        dets = face_detector(frame, 1)\n",
    "        faces = []\n",
    "        for i, d in enumerate(dets):\n",
    "            left, top, right, bottom = d.left(), d.top(), d.right(), d.bottom()\n",
    "            if right - left > 20:\n",
    "                face = frame[top:bottom, left:right]\n",
    "                face = torch.stack([face_transforms(Image.fromarray(face, 'RGB'))], dim = 0).to(device)\n",
    "                output_face = G_faces(face).squeeze(0).detach()\n",
    "                left = int(left * 1024/1280)\n",
    "                top = int(top * 1024/1280)\n",
    "                right = int(right * 1024/1280)\n",
    "                bottom = int(bottom * 1024/1280)\n",
    "                face_upsample = transforms.Compose([\n",
    "                    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                    transforms.Resize((bottom-top, right-left)), \n",
    "                    #transforms.ToPILImage()\n",
    "                ])\n",
    "                output_face = face_upsample(output_face)\n",
    "                #output_face = np.array(output_face)\n",
    "                #output_face = output_face.cpu().numpy().transpose(1,2,0)\n",
    "                output_frame[:,top:bottom, left:right] = output_face\n",
    "                \n",
    "        #output_frame = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(output_frame) \n",
    "        save_image(output_frame, 'output_movies/test.png', normalize=True)\n",
    "        #cv2.imwrite('output_movies/test.png', output_frame)\n",
    "        output.write(cv2.imread('output_movies/test.png', 1))\n",
    "    if frame_count >= start + video_length:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
